{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1z4v3eeESDA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report, log_loss\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score , auc\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeXS-3mLlztw",
        "outputId": "80f47b28-ad1a-4068-d4f3-1622a403ada4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grl0Jt9IEih5"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Final Defense (Atik & Rad)/Typhoid/Typhoid-main-file/Final_Typhoid_F_Encoded.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZWfNVRfqIB7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efrC38DREa1B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "wxcOO_NUqF65",
        "outputId": "c528dea2-8888-472e-8a5f-33efc03a0ce2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               age          sex     headache  RETRO-OCULAR PAIN  \\\n",
              "count  1742.000000  1746.000000  1746.000000        1746.000000   \n",
              "mean     33.758037     0.506873     0.796105           0.252577   \n",
              "std      20.199397     0.500096     0.403007           0.434615   \n",
              "min       0.000000     0.000000     0.000000           0.000000   \n",
              "25%      18.000000     0.000000     1.000000           0.000000   \n",
              "50%      31.000000     1.000000     1.000000           0.000000   \n",
              "75%      49.000000     1.000000     1.000000           1.000000   \n",
              "max      86.000000     1.000000     1.000000           1.000000   \n",
              "\n",
              "       muscle or muscle joint pain       NAUSEA         Rash  fast heart rate  \\\n",
              "count                  1746.000000  1746.000000  1746.000000      1746.000000   \n",
              "mean                      0.676403     0.505727     0.166094         0.170103   \n",
              "std                       0.467982     0.500110     0.372272         0.375831   \n",
              "min                       0.000000     0.000000     0.000000         0.000000   \n",
              "25%                       0.000000     0.000000     0.000000         0.000000   \n",
              "50%                       1.000000     1.000000     0.000000         0.000000   \n",
              "75%                       1.000000     1.000000     0.000000         0.000000   \n",
              "max                       1.000000     1.000000     1.000000         1.000000   \n",
              "\n",
              "       bloody cough  less urination  ...  Diarrhea or constipation  \\\n",
              "count   1746.000000     1746.000000  ...               1746.000000   \n",
              "mean       0.030355        0.147766  ...                  0.532073   \n",
              "std        0.171612        0.354970  ...                  0.499113   \n",
              "min        0.000000        0.000000  ...                  0.000000   \n",
              "25%        0.000000        0.000000  ...                  0.000000   \n",
              "50%        0.000000        0.000000  ...                  1.000000   \n",
              "75%        0.000000        0.000000  ...                  1.000000   \n",
              "max        1.000000        1.000000  ...                  1.000000   \n",
              "\n",
              "       Loss of appetite        Cough      fatigue  weight loss  \\\n",
              "count       1746.000000  1746.000000  1746.000000  1746.000000   \n",
              "mean           0.499427     0.523482     0.567583     0.552692   \n",
              "std            0.500143     0.499591     0.495553     0.497358   \n",
              "min            0.000000     0.000000     0.000000     0.000000   \n",
              "25%            0.000000     0.000000     0.000000     0.000000   \n",
              "50%            0.000000     1.000000     1.000000     1.000000   \n",
              "75%            1.000000     1.000000     1.000000     1.000000   \n",
              "max            1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "       Swollen stomach  Abdominal pain  Difficulty paying attention  \\\n",
              "count      1746.000000     1746.000000                  1746.000000   \n",
              "mean          0.519473        0.521191                     0.536082   \n",
              "std           0.499764        0.499694                     0.498839   \n",
              "min           0.000000        0.000000                     0.000000   \n",
              "25%           0.000000        0.000000                     0.000000   \n",
              "50%           1.000000        1.000000                     1.000000   \n",
              "75%           1.000000        1.000000                     1.000000   \n",
              "max           1.000000        1.000000                     1.000000   \n",
              "\n",
              "         Agitation  hallucinations  \n",
              "count  1746.000000     1746.000000  \n",
              "mean      0.561856        0.548110  \n",
              "std       0.496301        0.497823  \n",
              "min       0.000000        0.000000  \n",
              "25%       0.000000        0.000000  \n",
              "50%       1.000000        1.000000  \n",
              "75%       1.000000        1.000000  \n",
              "max       1.000000        1.000000  \n",
              "\n",
              "[8 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bb99303-f1b2-4ab6-ab0a-b7316aa5f6b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>headache</th>\n",
              "      <th>RETRO-OCULAR PAIN</th>\n",
              "      <th>muscle or muscle joint pain</th>\n",
              "      <th>NAUSEA</th>\n",
              "      <th>Rash</th>\n",
              "      <th>fast heart rate</th>\n",
              "      <th>bloody cough</th>\n",
              "      <th>less urination</th>\n",
              "      <th>...</th>\n",
              "      <th>Diarrhea or constipation</th>\n",
              "      <th>Loss of appetite</th>\n",
              "      <th>Cough</th>\n",
              "      <th>fatigue</th>\n",
              "      <th>weight loss</th>\n",
              "      <th>Swollen stomach</th>\n",
              "      <th>Abdominal pain</th>\n",
              "      <th>Difficulty paying attention</th>\n",
              "      <th>Agitation</th>\n",
              "      <th>hallucinations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1742.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "      <td>1746.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>33.758037</td>\n",
              "      <td>0.506873</td>\n",
              "      <td>0.796105</td>\n",
              "      <td>0.252577</td>\n",
              "      <td>0.676403</td>\n",
              "      <td>0.505727</td>\n",
              "      <td>0.166094</td>\n",
              "      <td>0.170103</td>\n",
              "      <td>0.030355</td>\n",
              "      <td>0.147766</td>\n",
              "      <td>...</td>\n",
              "      <td>0.532073</td>\n",
              "      <td>0.499427</td>\n",
              "      <td>0.523482</td>\n",
              "      <td>0.567583</td>\n",
              "      <td>0.552692</td>\n",
              "      <td>0.519473</td>\n",
              "      <td>0.521191</td>\n",
              "      <td>0.536082</td>\n",
              "      <td>0.561856</td>\n",
              "      <td>0.548110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>20.199397</td>\n",
              "      <td>0.500096</td>\n",
              "      <td>0.403007</td>\n",
              "      <td>0.434615</td>\n",
              "      <td>0.467982</td>\n",
              "      <td>0.500110</td>\n",
              "      <td>0.372272</td>\n",
              "      <td>0.375831</td>\n",
              "      <td>0.171612</td>\n",
              "      <td>0.354970</td>\n",
              "      <td>...</td>\n",
              "      <td>0.499113</td>\n",
              "      <td>0.500143</td>\n",
              "      <td>0.499591</td>\n",
              "      <td>0.495553</td>\n",
              "      <td>0.497358</td>\n",
              "      <td>0.499764</td>\n",
              "      <td>0.499694</td>\n",
              "      <td>0.498839</td>\n",
              "      <td>0.496301</td>\n",
              "      <td>0.497823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>31.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>49.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>86.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bb99303-f1b2-4ab6-ab0a-b7316aa5f6b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bb99303-f1b2-4ab6-ab0a-b7316aa5f6b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bb99303-f1b2-4ab6-ab0a-b7316aa5f6b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmWyWor_ErXw",
        "outputId": "5a5bdc72-0603-41de-d4aa-f4415ec67091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1746 entries, 0 to 1745\n",
            "Data columns (total 29 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   age                           1742 non-null   float64\n",
            " 1   sex                           1746 non-null   int64  \n",
            " 2   headache                      1746 non-null   int64  \n",
            " 3   RETRO-OCULAR PAIN             1746 non-null   int64  \n",
            " 4   muscle or muscle joint pain   1746 non-null   int64  \n",
            " 5   NAUSEA                        1746 non-null   int64  \n",
            " 6   Rash                          1746 non-null   int64  \n",
            " 7   fast heart rate               1746 non-null   int64  \n",
            " 8   bloody cough                  1746 non-null   int64  \n",
            " 9   less urination                1746 non-null   int64  \n",
            " 10  Nose Bleeding                 1732 non-null   float64\n",
            " 11  Shortness of breath-asphyxia  1732 non-null   float64\n",
            " 12  SENSORY CHANGE                1732 non-null   float64\n",
            " 13  VOMITING                      1732 non-null   float64\n",
            " 14  traveler                      1721 non-null   float64\n",
            " 15  Swollen eyelid                1719 non-null   float64\n",
            " 16  muscle stiffness              1719 non-null   float64\n",
            " 17  Sweating                      1746 non-null   int64  \n",
            " 18  Diarrhea or constipation      1746 non-null   int64  \n",
            " 19  Loss of appetite              1746 non-null   int64  \n",
            " 20  Cough                         1746 non-null   int64  \n",
            " 21  fatigue                       1746 non-null   int64  \n",
            " 22  weight loss                   1746 non-null   int64  \n",
            " 23  Swollen stomach               1746 non-null   int64  \n",
            " 24  Abdominal pain                1746 non-null   int64  \n",
            " 25  Difficulty paying attention   1746 non-null   int64  \n",
            " 26  Agitation                     1746 non-null   int64  \n",
            " 27  hallucinations                1746 non-null   int64  \n",
            " 28  Fever Type                    1746 non-null   object \n",
            "dtypes: float64(8), int64(20), object(1)\n",
            "memory usage: 395.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qUou7kuEsd4",
        "outputId": "62183075-4fb5-4bd0-a64b-042553543df1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                              4\n",
              "sex                              0\n",
              "headache                         0\n",
              "RETRO-OCULAR PAIN                0\n",
              "muscle or muscle joint pain      0\n",
              "NAUSEA                           0\n",
              "Rash                             0\n",
              "fast heart rate                  0\n",
              "bloody cough                     0\n",
              "less urination                   0\n",
              "Nose Bleeding                   14\n",
              "Shortness of breath-asphyxia    14\n",
              "SENSORY CHANGE                  14\n",
              "VOMITING                        14\n",
              "traveler                        25\n",
              "Swollen eyelid                  27\n",
              "muscle stiffness                27\n",
              "Sweating                         0\n",
              "Diarrhea or constipation         0\n",
              "Loss of appetite                 0\n",
              "Cough                            0\n",
              "fatigue                          0\n",
              "weight loss                      0\n",
              "Swollen stomach                  0\n",
              "Abdominal pain                   0\n",
              "Difficulty paying attention      0\n",
              "Agitation                        0\n",
              "hallucinations                   0\n",
              "Fever Type                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHJQ5NIpEw8g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jslW2L6YE9qZ"
      },
      "source": [
        "# Missing Value Handlig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk8rrT28Hsuk"
      },
      "source": [
        "Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo-_fhO5FAzQ"
      },
      "outputs": [],
      "source": [
        "df['age'].fillna(int(df['age'].mean()), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE2JlJb7FyxS"
      },
      "source": [
        "Nose Bleeding "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2gtuRJWF8k9",
        "outputId": "c7e2ff0e-032f-42b6-dd0d-b4a02e2fc648"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1661\n",
              "1.0      71\n",
              "Name: Nose Bleeding, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df['Nose Bleeding'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_cmXqz-FsOH"
      },
      "outputs": [],
      "source": [
        "df['Nose Bleeding'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41ceMqzoGTkm"
      },
      "source": [
        "Shortness of breath-asphyxia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "komaGYIDFsK4",
        "outputId": "b18a3a10-0bbc-43ee-8d55-46a56f6482e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1470\n",
              "1.0     262\n",
              "Name: Shortness of breath-asphyxia, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df['Shortness of breath-asphyxia'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYXNqwL1GSy9"
      },
      "outputs": [],
      "source": [
        "df['Shortness of breath-asphyxia'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akGmbViQGe4t"
      },
      "source": [
        "SENSORY CHANGE "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFBLHMFiGSv6",
        "outputId": "659efc42-ed60-44d3-e6df-b6bf0b9328f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1564\n",
              "1.0     168\n",
              "Name: SENSORY CHANGE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df['SENSORY CHANGE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW4uZ244GSs6"
      },
      "outputs": [],
      "source": [
        "df['SENSORY CHANGE'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k56r97RGsL-"
      },
      "source": [
        "VOMITING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoV3xoKqGSpU",
        "outputId": "ace7f08d-5251-49f7-8fcf-0adb1ad7a261"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1704\n",
              "1.0      28\n",
              "Name: VOMITING, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df['VOMITING'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ylt6PEFtGSlp"
      },
      "outputs": [],
      "source": [
        "df['VOMITING'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fci8qM5BHB2M"
      },
      "source": [
        "traveler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWkxYLbIG1vz",
        "outputId": "15e77be5-2c62-47b5-8e6c-159790636fad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1177\n",
              "1.0     544\n",
              "Name: traveler, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df['traveler'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyrQsi7RG1s3"
      },
      "outputs": [],
      "source": [
        "df['traveler'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMdsUc9qHX0x"
      },
      "source": [
        "Swollen eyelid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1coOp2aVHA9R",
        "outputId": "3927abe0-c755-4efe-aab6-99d6f6c5112c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1433\n",
              "1.0     286\n",
              "Name: Swollen eyelid, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df['Swollen eyelid'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iESG0tnVHAzB"
      },
      "outputs": [],
      "source": [
        "df['Swollen eyelid'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT13jLzjHdgZ"
      },
      "source": [
        "muscle stiffness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1G-M2sZHOTs",
        "outputId": "7359c2eb-d6f5-4a21-ae0a-f7c86cf801bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1609\n",
              "1.0     110\n",
              "Name: muscle stiffness, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df['muscle stiffness'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q6zXoeiHOQg"
      },
      "outputs": [],
      "source": [
        "df['muscle stiffness'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDPNXsiRHh43"
      },
      "outputs": [],
      "source": [
        "df=df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpik7eWgIV3X",
        "outputId": "e8b87337-b29e-4635-815e-91a8ba4b7882"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                             0\n",
              "sex                             0\n",
              "headache                        0\n",
              "RETRO-OCULAR PAIN               0\n",
              "muscle or muscle joint pain     0\n",
              "NAUSEA                          0\n",
              "Rash                            0\n",
              "fast heart rate                 0\n",
              "bloody cough                    0\n",
              "less urination                  0\n",
              "Nose Bleeding                   0\n",
              "Shortness of breath-asphyxia    0\n",
              "SENSORY CHANGE                  0\n",
              "VOMITING                        0\n",
              "traveler                        0\n",
              "Swollen eyelid                  0\n",
              "muscle stiffness                0\n",
              "Sweating                        0\n",
              "Diarrhea or constipation        0\n",
              "Loss of appetite                0\n",
              "Cough                           0\n",
              "fatigue                         0\n",
              "weight loss                     0\n",
              "Swollen stomach                 0\n",
              "Abdominal pain                  0\n",
              "Difficulty paying attention     0\n",
              "Agitation                       0\n",
              "hallucinations                  0\n",
              "Fever Type                      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3iZkagRIDKv"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqczHGrMIGOW",
        "outputId": "2295ffbe-6f18-4ce9-9d3c-99c99ceffb7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1746 entries, 0 to 1745\n",
            "Data columns (total 29 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   age                           1746 non-null   float64\n",
            " 1   sex                           1746 non-null   int64  \n",
            " 2   headache                      1746 non-null   int64  \n",
            " 3   RETRO-OCULAR PAIN             1746 non-null   int64  \n",
            " 4   muscle or muscle joint pain   1746 non-null   int64  \n",
            " 5   NAUSEA                        1746 non-null   int64  \n",
            " 6   Rash                          1746 non-null   int64  \n",
            " 7   fast heart rate               1746 non-null   int64  \n",
            " 8   bloody cough                  1746 non-null   int64  \n",
            " 9   less urination                1746 non-null   int64  \n",
            " 10  Nose Bleeding                 1746 non-null   float64\n",
            " 11  Shortness of breath-asphyxia  1746 non-null   float64\n",
            " 12  SENSORY CHANGE                1746 non-null   float64\n",
            " 13  VOMITING                      1746 non-null   float64\n",
            " 14  traveler                      1746 non-null   float64\n",
            " 15  Swollen eyelid                1746 non-null   float64\n",
            " 16  muscle stiffness              1746 non-null   float64\n",
            " 17  Sweating                      1746 non-null   int64  \n",
            " 18  Diarrhea or constipation      1746 non-null   int64  \n",
            " 19  Loss of appetite              1746 non-null   int64  \n",
            " 20  Cough                         1746 non-null   int64  \n",
            " 21  fatigue                       1746 non-null   int64  \n",
            " 22  weight loss                   1746 non-null   int64  \n",
            " 23  Swollen stomach               1746 non-null   int64  \n",
            " 24  Abdominal pain                1746 non-null   int64  \n",
            " 25  Difficulty paying attention   1746 non-null   int64  \n",
            " 26  Agitation                     1746 non-null   int64  \n",
            " 27  hallucinations                1746 non-null   int64  \n",
            " 28  Fever Type                    1746 non-null   object \n",
            "dtypes: float64(8), int64(20), object(1)\n",
            "memory usage: 409.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYc0iDqtITPG"
      },
      "outputs": [],
      "source": [
        "def target_attribute(x):\n",
        "  if x=='Typhoid':\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "df['Fever Type']=df['Fever Type'].apply(target_attribute)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwk-Qk-xJ2xF",
        "outputId": "1365e703-9e2b-4742-cf07-a6df28fb393e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1746 entries, 0 to 1745\n",
            "Data columns (total 29 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   age                           1746 non-null   float64\n",
            " 1   sex                           1746 non-null   int64  \n",
            " 2   headache                      1746 non-null   int64  \n",
            " 3   RETRO-OCULAR PAIN             1746 non-null   int64  \n",
            " 4   muscle or muscle joint pain   1746 non-null   int64  \n",
            " 5   NAUSEA                        1746 non-null   int64  \n",
            " 6   Rash                          1746 non-null   int64  \n",
            " 7   fast heart rate               1746 non-null   int64  \n",
            " 8   bloody cough                  1746 non-null   int64  \n",
            " 9   less urination                1746 non-null   int64  \n",
            " 10  Nose Bleeding                 1746 non-null   float64\n",
            " 11  Shortness of breath-asphyxia  1746 non-null   float64\n",
            " 12  SENSORY CHANGE                1746 non-null   float64\n",
            " 13  VOMITING                      1746 non-null   float64\n",
            " 14  traveler                      1746 non-null   float64\n",
            " 15  Swollen eyelid                1746 non-null   float64\n",
            " 16  muscle stiffness              1746 non-null   float64\n",
            " 17  Sweating                      1746 non-null   int64  \n",
            " 18  Diarrhea or constipation      1746 non-null   int64  \n",
            " 19  Loss of appetite              1746 non-null   int64  \n",
            " 20  Cough                         1746 non-null   int64  \n",
            " 21  fatigue                       1746 non-null   int64  \n",
            " 22  weight loss                   1746 non-null   int64  \n",
            " 23  Swollen stomach               1746 non-null   int64  \n",
            " 24  Abdominal pain                1746 non-null   int64  \n",
            " 25  Difficulty paying attention   1746 non-null   int64  \n",
            " 26  Agitation                     1746 non-null   int64  \n",
            " 27  hallucinations                1746 non-null   int64  \n",
            " 28  Fever Type                    1746 non-null   int64  \n",
            "dtypes: float64(8), int64(21)\n",
            "memory usage: 409.2 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lSfvOygJ45m",
        "outputId": "76c4b271-f1c5-4434-bd3c-64fb989d7b78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'sex', 'headache', 'RETRO-OCULAR PAIN',\n",
              "       'muscle or muscle joint pain', 'NAUSEA', 'Rash', 'fast heart rate',\n",
              "       'bloody cough', 'less urination', 'Nose Bleeding',\n",
              "       'Shortness of breath-asphyxia', 'SENSORY CHANGE', 'VOMITING',\n",
              "       'traveler', 'Swollen eyelid', 'muscle stiffness', 'Sweating',\n",
              "       'Diarrhea or constipation', 'Loss of appetite', 'Cough', 'fatigue',\n",
              "       'weight loss', 'Swollen stomach', 'Abdominal pain',\n",
              "       'Difficulty paying attention', 'Agitation', 'hallucinations',\n",
              "       'Fever Type'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5pw9Hx1J6yr"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLaJ6vqnD7W8",
        "outputId": "57284711-27c9-482d-e9a9-05c3db05d570"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1746, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Vcdetj4D9V1"
      },
      "outputs": [],
      "source": [
        "df=df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBsT2BNeEEFo",
        "outputId": "ab3d3f5f-8c11-448e-8987-0060f7b0dabe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1504, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VZj_2efJ-Ht"
      },
      "outputs": [],
      "source": [
        "x=df.drop(['Fever Type'],axis=1)\n",
        "y=df['Fever Type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVSNct75KYkl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=.25,random_state=0,stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_iFXUP2MJ0k"
      },
      "outputs": [],
      "source": [
        "def roc_auc_values(MODEL):\n",
        "  probs = MODEL.predict_proba(xtest)\n",
        "  probs = probs[:, 1]\n",
        "  auc = roc_auc_score(ytest, probs)\n",
        "  fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "  a={'tpr':tpr,\n",
        "     'fpr':fpr,\n",
        "     'auc':auc\n",
        "    }\n",
        "  return a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9LdysYwKa3m",
        "outputId": "379d3e1f-b2d0-4179-8284-962ea24ea18b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  1 192]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97       183\n",
            "           1       0.96      0.99      0.98       193\n",
            "\n",
            "    accuracy                           0.98       376\n",
            "   macro avg       0.98      0.98      0.98       376\n",
            "weighted avg       0.98      0.98      0.98       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.976063829787234\n",
            "Training accuracy: 99.7340425531915\n",
            "F1 Score : 0.9760147993791065\n",
            "Precision : 0.9771590909090908\n",
            "Recall : 0.9755514029276027\n",
            "AUC = 0.980\n",
            "Sensitivity :  0.9943181818181818\n",
            "Specificity :  0.96\n",
            "false positive rate :  0.04\n",
            "false negative rate :  0.005681818181818182\n",
            "Negative Predictive Value :  0.9948186528497409\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.023936170212765957\n",
            "10 fold cross validation:  [0.98013245 0.92715232 0.96688742 0.97350993 0.94       0.98666667\n",
            " 0.96666667 0.97333333 0.97333333 0.98      ]\n",
            "Mean of 10 fold cross validation :  0.9667682119205298\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RF=RandomForestClassifier()\n",
        "RF.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, RF.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, RF.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',RF.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",RF.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, RF.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, RF.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, RF.predict(xtest),average='macro'))\n",
        "probs = RF.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, RF.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(RF,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "rf=roc_auc_values(RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfONSlDaMSqk"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DT=DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs_TeFhHMph9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95837372-5dc7-4ba9-83b5-82ab2e1ec3d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [ 21 172]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       183\n",
            "           1       0.96      0.89      0.92       193\n",
            "\n",
            "    accuracy                           0.92       376\n",
            "   macro avg       0.92      0.92      0.92       376\n",
            "weighted avg       0.93      0.92      0.92       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.9228723404255319\n",
            "Training accuracy: 99.7340425531915\n",
            "F1 Score : 0.9228510626257383\n",
            "Precision : 0.9250401046943599\n",
            "Recall : 0.9228723404255319\n",
            "AUC = 0.929\n",
            "Sensitivity :  0.8928571428571429\n",
            "Specificity :  0.9555555555555556\n",
            "false positive rate :  0.044444444444444446\n",
            "false negative rate :  0.10714285714285714\n",
            "Negative Predictive Value :  0.8911917098445595\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.07712765957446809\n",
            "10 fold cross validation:  [0.96688742 0.91390728 0.96688742 0.94701987 0.92666667 0.95333333\n",
            " 0.94       0.96666667 0.96       0.95333333]\n",
            "Mean of 10 fold cross validation :  0.9494701986754966\n"
          ]
        }
      ],
      "source": [
        "DT.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, DT.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, DT.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',DT.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",DT.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, DT.predict(xtest),average='weighted'))\n",
        "print(\"Precision :\", precision_score(ytest, DT.predict(xtest),average='weighted'))\n",
        "print(\"Recall :\", recall_score(ytest, DT.predict(xtest),average='weighted'))\n",
        "probs = DT.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, DT.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(DT,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "dt=roc_auc_values(DT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wyk-LJDMyy8"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ABC = AdaBoostClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpCnXVAFM29E",
        "outputId": "d4386b22-83af-457d-8657-9978444980e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  1 192]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97       183\n",
            "           1       0.96      0.99      0.98       193\n",
            "\n",
            "    accuracy                           0.98       376\n",
            "   macro avg       0.98      0.98      0.98       376\n",
            "weighted avg       0.98      0.98      0.98       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.976063829787234\n",
            "Training accuracy: 97.6063829787234\n",
            "F1 Score : 0.9760147993791065\n",
            "Precision : 0.9771590909090908\n",
            "Recall : 0.9755514029276027\n",
            "AUC = 0.985\n",
            "Sensitivity :  0.9943181818181818\n",
            "Specificity :  0.96\n",
            "false positive rate :  0.04\n",
            "false negative rate :  0.005681818181818182\n",
            "Negative Predictive Value :  0.9948186528497409\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.023936170212765957\n",
            "10 fold cross validation:  [0.99337748 0.94039735 0.98013245 0.98013245 0.94666667 0.98666667\n",
            " 0.96       0.98666667 0.98666667 0.98      ]\n",
            "Mean of 10 fold cross validation :  0.9740706401766005\n"
          ]
        }
      ],
      "source": [
        "ABC.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, ABC.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, ABC.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',ABC.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",ABC.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, ABC.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, ABC.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, ABC.predict(xtest),average='macro'))\n",
        "probs = ABC.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, ABC.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(ABC,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "abc=roc_auc_values(ABC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czaJXbO9M8vE"
      },
      "outputs": [],
      "source": [
        "import xgboost\n",
        "XGB=xgboost.XGBClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xStaRJ2cM_1E",
        "outputId": "dead8851-2dfa-478c-8756-bb93c1ebded0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  0 193]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98       183\n",
            "           1       0.96      1.00      0.98       193\n",
            "\n",
            "    accuracy                           0.98       376\n",
            "   macro avg       0.98      0.98      0.98       376\n",
            "weighted avg       0.98      0.98      0.98       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.9787234042553191\n",
            "Training accuracy: 97.6063829787234\n",
            "F1 Score : 0.9786745313784987\n",
            "Precision : 0.9800995024875622\n",
            "Recall : 0.9781420765027322\n",
            "AUC = 0.986\n",
            "Sensitivity :  1.0\n",
            "Specificity :  0.9601990049751243\n",
            "false positive rate :  0.03980099502487562\n",
            "false negative rate :  0.0\n",
            "Negative Predictive Value :  1.0\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.02127659574468085\n",
            "10 fold cross validation:  [0.99337748 0.94701987 0.98013245 0.98013245 0.94666667 0.98666667\n",
            " 0.97333333 0.98666667 0.99333333 0.98      ]\n",
            "Mean of 10 fold cross validation :  0.9767328918322298\n"
          ]
        }
      ],
      "source": [
        "XGB.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, XGB.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, XGB.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',XGB.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",XGB.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, XGB.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, XGB.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, XGB.predict(xtest),average='macro'))\n",
        "probs = XGB.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, XGB.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(XGB,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "xgb=roc_auc_values(XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEZUMOG4NHw9"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "MLP = MLPClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoLWK2YDNHt-",
        "outputId": "6c49946a-e4dc-4465-c591-b471178e406e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  0 193]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98       183\n",
            "           1       0.96      1.00      0.98       193\n",
            "\n",
            "    accuracy                           0.98       376\n",
            "   macro avg       0.98      0.98      0.98       376\n",
            "weighted avg       0.98      0.98      0.98       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.9787234042553191\n",
            "Training accuracy: 98.22695035460993\n",
            "F1 Score : 0.9786745313784987\n",
            "Precision : 0.9800995024875622\n",
            "Recall : 0.9781420765027322\n",
            "AUC = 0.987\n",
            "Sensitivity :  1.0\n",
            "Specificity :  0.9601990049751243\n",
            "false positive rate :  0.03980099502487562\n",
            "false negative rate :  0.0\n",
            "Negative Predictive Value :  1.0\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.02127659574468085\n",
            "10 fold cross validation:  [0.99337748 0.94701987 0.96688742 0.98013245 0.94666667 0.97333333\n",
            " 0.98       0.98666667 0.99333333 0.98      ]\n",
            "Mean of 10 fold cross validation :  0.9747417218543047\n"
          ]
        }
      ],
      "source": [
        "MLP.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, MLP.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, MLP.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',MLP.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",MLP.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, MLP.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, MLP.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, MLP.predict(xtest),average='macro'))\n",
        "probs = MLP.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, MLP.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(MLP,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "mlp=roc_auc_values(MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaQ3rXmaNHrQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import  ExtraTreesClassifier\n",
        "ETC=ExtraTreesClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hoc24FqUNHoT",
        "outputId": "76ea988d-f0ce-48ae-948a-d1030b83c74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  4 189]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       183\n",
            "           1       0.96      0.98      0.97       193\n",
            "\n",
            "    accuracy                           0.97       376\n",
            "   macro avg       0.97      0.97      0.97       376\n",
            "weighted avg       0.97      0.97      0.97       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.9680851063829787\n",
            "Training accuracy: 99.7340425531915\n",
            "F1 Score : 0.9680407989800255\n",
            "Precision : 0.9685222471145394\n",
            "Recall : 0.967779382202214\n",
            "AUC = 0.979\n",
            "Sensitivity :  0.9776536312849162\n",
            "Specificity :  0.9593908629441624\n",
            "false positive rate :  0.04060913705583756\n",
            "false negative rate :  0.0223463687150838\n",
            "Negative Predictive Value :  0.9792746113989638\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.031914893617021274\n",
            "10 fold cross validation:  [0.97350993 0.92715232 0.9602649  0.97350993 0.93333333 0.98\n",
            " 0.96666667 0.96666667 0.96666667 0.97333333]\n",
            "Mean of 10 fold cross validation :  0.9621103752759381\n"
          ]
        }
      ],
      "source": [
        "ETC.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, ETC.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, ETC.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',ETC.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",ETC.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, ETC.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, ETC.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, ETC.predict(xtest),average='macro'))\n",
        "probs = ETC.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, ETC.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(ETC,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "etc=roc_auc_values(ETC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0T4ebxBNHll"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import  GradientBoostingClassifier\n",
        "GBC= GradientBoostingClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9FevXS2NHif",
        "outputId": "1cf89aa4-3462-45a3-a0cd-62368545fe3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  0 193]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98       183\n",
            "           1       0.96      1.00      0.98       193\n",
            "\n",
            "    accuracy                           0.98       376\n",
            "   macro avg       0.98      0.98      0.98       376\n",
            "weighted avg       0.98      0.98      0.98       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.9787234042553191\n",
            "Training accuracy: 98.22695035460993\n",
            "F1 Score : 0.9786745313784987\n",
            "Precision : 0.9800995024875622\n",
            "Recall : 0.9781420765027322\n",
            "AUC = 0.986\n",
            "Sensitivity :  1.0\n",
            "Specificity :  0.9601990049751243\n",
            "false positive rate :  0.03980099502487562\n",
            "false negative rate :  0.0\n",
            "Negative Predictive Value :  1.0\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.02127659574468085\n",
            "10 fold cross validation:  [0.99337748 0.94701987 0.98013245 0.97350993 0.94       0.98\n",
            " 0.97333333 0.98666667 0.99333333 0.98666667]\n",
            "Mean of 10 fold cross validation :  0.9754039735099338\n"
          ]
        }
      ],
      "source": [
        "GBC.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, GBC.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, GBC.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',GBC.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",GBC.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, GBC.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, GBC.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, GBC.predict(xtest),average='macro'))\n",
        "probs = GBC.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, GBC.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(GBC,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "gbc=roc_auc_values(GBC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agGEHGHTNHf6"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "SGDC = SGDClassifier(loss='log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShKdutPGNHc8",
        "outputId": "6a10510a-be74-4fa4-93a0-a36ab431d16a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  7 186]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       183\n",
            "           1       0.96      0.96      0.96       193\n",
            "\n",
            "    accuracy                           0.96       376\n",
            "   macro avg       0.96      0.96      0.96       376\n",
            "weighted avg       0.96      0.96      0.96       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.9601063829787234\n",
            "Training accuracy: 94.41489361702128\n",
            "F1 Score : 0.9600722098332801\n",
            "Precision : 0.9601506740681999\n",
            "Recall : 0.9600073614768254\n",
            "AUC = 0.976\n",
            "Sensitivity :  0.9615384615384616\n",
            "Specificity :  0.9587628865979382\n",
            "false positive rate :  0.041237113402061855\n",
            "false negative rate :  0.038461538461538464\n",
            "Negative Predictive Value :  0.9637305699481865\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.0398936170212766\n",
            "10 fold cross validation:  [0.98675497 0.94039735 0.94701987 0.9602649  0.94666667 0.98666667\n",
            " 0.94666667 0.98       0.98       0.96      ]\n",
            "Mean of 10 fold cross validation :  0.9634437086092718\n"
          ]
        }
      ],
      "source": [
        "SGDC.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, SGDC.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, SGDC.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',SGDC.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",SGDC.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, SGDC.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, SGDC.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, SGDC.predict(xtest),average='macro'))\n",
        "probs = SGDC.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, SGDC.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(SGDC,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "sgdc=roc_auc_values(SGDC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCdPIIxGNHaN"
      },
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "HGB=HistGradientBoostingClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai3-NXwbNHXO",
        "outputId": "ce8556a0-d97a-4c50-a311-0ffd2c6a3d08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  5 188]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96       183\n",
            "           1       0.96      0.97      0.97       193\n",
            "\n",
            "    accuracy                           0.97       376\n",
            "   macro avg       0.97      0.97      0.97       376\n",
            "weighted avg       0.97      0.97      0.97       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.9654255319148937\n",
            "Training accuracy: 99.55673758865248\n",
            "F1 Score : 0.9653841523437223\n",
            "Precision : 0.965702947845805\n",
            "Recall : 0.9651887086270845\n",
            "AUC = 0.984\n",
            "Sensitivity :  0.9722222222222222\n",
            "Specificity :  0.9591836734693877\n",
            "false positive rate :  0.04081632653061224\n",
            "false negative rate :  0.027777777777777776\n",
            "Negative Predictive Value :  0.9740932642487047\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.034574468085106384\n",
            "10 fold cross validation:  [0.98013245 0.93377483 0.97350993 0.97350993 0.93333333 0.98\n",
            " 0.97333333 0.98       0.98666667 0.98      ]\n",
            "Mean of 10 fold cross validation :  0.9694260485651215\n"
          ]
        }
      ],
      "source": [
        "HGB.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, HGB.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, HGB.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',HGB.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",HGB.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, HGB.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, HGB.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, HGB.predict(xtest),average='macro'))\n",
        "probs = HGB.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, HGB.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(HGB,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "hgb=roc_auc_values(HGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkbUnLHcNHUR"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "LGBM=LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21SjLDHONHQ0",
        "outputId": "fa208e74-e919-4cc7-d75c-35a1111e5e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  5 188]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96       183\n",
            "           1       0.96      0.97      0.97       193\n",
            "\n",
            "    accuracy                           0.97       376\n",
            "   macro avg       0.97      0.97      0.97       376\n",
            "weighted avg       0.97      0.97      0.97       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.9654255319148937\n",
            "Training accuracy: 99.64539007092199\n",
            "F1 Score : 0.9653841523437223\n",
            "Precision : 0.965702947845805\n",
            "Recall : 0.9651887086270845\n",
            "AUC = 0.984\n",
            "Sensitivity :  0.9722222222222222\n",
            "Specificity :  0.9591836734693877\n",
            "false positive rate :  0.04081632653061224\n",
            "false negative rate :  0.027777777777777776\n",
            "Negative Predictive Value :  0.9740932642487047\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.034574468085106384\n",
            "10 fold cross validation:  [0.98013245 0.93377483 0.97350993 0.97350993 0.94       0.98\n",
            " 0.97333333 0.98       0.98666667 0.98      ]\n",
            "Mean of 10 fold cross validation :  0.9700927152317881\n"
          ]
        }
      ],
      "source": [
        "LGBM.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, LGBM.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, LGBM.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',LGBM.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",LGBM.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, LGBM.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, LGBM.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, LGBM.predict(xtest),average='macro'))\n",
        "probs = LGBM.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, LGBM.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(LGBM,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "lgbm=roc_auc_values(LGBM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvdPXWgGNHNP"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "KNNC=KNeighborsClassifier(n_neighbors=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmK0RzwcNTgO",
        "outputId": "c788faa1-1f22-4e8d-bed3-21ab8cb4ce70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[174   9]\n",
            " [  0 193]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97       183\n",
            "           1       0.96      1.00      0.98       193\n",
            "\n",
            "    accuracy                           0.98       376\n",
            "   macro avg       0.98      0.98      0.98       376\n",
            "weighted avg       0.98      0.98      0.98       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.976063829787234\n",
            "Training accuracy: 96.09929078014184\n",
            "F1 Score : 0.9760025529199021\n",
            "Precision : 0.9777227722772277\n",
            "Recall : 0.9754098360655737\n",
            "AUC = 0.979\n",
            "Sensitivity :  1.0\n",
            "Specificity :  0.9554455445544554\n",
            "false positive rate :  0.04455445544554455\n",
            "false negative rate :  0.0\n",
            "Negative Predictive Value :  1.0\n",
            "False Discovery rate :  0.04918032786885246\n",
            "Mean Absolute Error: 0.023936170212765957\n",
            "10 fold cross validation:  [0.97350993 0.92715232 0.94039735 0.97350993 0.93333333 0.96666667\n",
            " 0.96666667 0.97333333 0.96666667 0.95333333]\n",
            "Mean of 10 fold cross validation :  0.957456953642384\n"
          ]
        }
      ],
      "source": [
        "KNNC.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, KNNC.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, KNNC.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',KNNC.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",KNNC.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, KNNC.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, KNNC.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, KNNC.predict(xtest),average='macro'))\n",
        "probs = KNNC.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, KNNC.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(KNNC,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "knnc=roc_auc_values(KNNC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REUKemvoNTdN"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "GNB = GaussianNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF38NipSNTaP",
        "outputId": "54c9c8ad-2152-40c1-e109-b4aa1f15ba28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  0 193]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98       183\n",
            "           1       0.96      1.00      0.98       193\n",
            "\n",
            "    accuracy                           0.98       376\n",
            "   macro avg       0.98      0.98      0.98       376\n",
            "weighted avg       0.98      0.98      0.98       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.9787234042553191\n",
            "Training accuracy: 97.4290780141844\n",
            "F1 Score : 0.9786745313784987\n",
            "Precision : 0.9800995024875622\n",
            "Recall : 0.9781420765027322\n",
            "AUC = 0.976\n",
            "Sensitivity :  1.0\n",
            "Specificity :  0.9601990049751243\n",
            "false positive rate :  0.03980099502487562\n",
            "false negative rate :  0.0\n",
            "Negative Predictive Value :  1.0\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.02127659574468085\n",
            "10 fold cross validation:  [0.98675497 0.94701987 0.95364238 0.97350993 0.94666667 0.98\n",
            " 0.96666667 0.96666667 0.98       0.96666667]\n",
            "Mean of 10 fold cross validation :  0.9667593818984548\n"
          ]
        }
      ],
      "source": [
        "GNB.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, GNB.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, GNB.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',GNB.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",GNB.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, GNB.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, GNB.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, GNB.predict(xtest),average='macro'))\n",
        "probs = GNB.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, GNB.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(GNB,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "gnb=roc_auc_values(GNB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn0FJvKENTXb"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression(multi_class='multinomial', max_iter=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM1miKGcNTUk",
        "outputId": "05c4d4d7-762b-4d26-d7c2-497034e0acec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  0 193]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98       183\n",
            "           1       0.96      1.00      0.98       193\n",
            "\n",
            "    accuracy                           0.98       376\n",
            "   macro avg       0.98      0.98      0.98       376\n",
            "weighted avg       0.98      0.98      0.98       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.9787234042553191\n",
            "Training accuracy: 97.6063829787234\n",
            "F1 Score : 0.9786745313784987\n",
            "Precision : 0.9800995024875622\n",
            "Recall : 0.9781420765027322\n",
            "AUC = 0.983\n",
            "Sensitivity :  1.0\n",
            "Specificity :  0.9601990049751243\n",
            "false positive rate :  0.03980099502487562\n",
            "false negative rate :  0.0\n",
            "Negative Predictive Value :  1.0\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.02127659574468085\n",
            "10 fold cross validation:  [0.98675497 0.94701987 0.98013245 0.98013245 0.94666667 0.98666667\n",
            " 0.97333333 0.98666667 0.99333333 0.98      ]\n",
            "Mean of 10 fold cross validation :  0.9760706401766006\n"
          ]
        }
      ],
      "source": [
        "LR.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, LR.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, LR.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',LR.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",LR.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, LR.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, LR.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, LR.predict(xtest),average='macro'))\n",
        "probs = LR.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, LR.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(LR,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "lr=roc_auc_values(LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfkTBEtINTRW"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "BC = BaggingClassifier(n_estimators = 500, max_samples = 0.5, max_features = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzEnvK4qNZak",
        "outputId": "ca57f440-ec0e-4ca1-8d7a-ddc86fc6278d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  0 193]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98       183\n",
            "           1       0.96      1.00      0.98       193\n",
            "\n",
            "    accuracy                           0.98       376\n",
            "   macro avg       0.98      0.98      0.98       376\n",
            "weighted avg       0.98      0.98      0.98       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.9787234042553191\n",
            "Training accuracy: 97.6063829787234\n",
            "F1 Score : 0.9786745313784987\n",
            "Precision : 0.9800995024875622\n",
            "Recall : 0.9781420765027322\n",
            "AUC = 0.977\n",
            "Sensitivity :  1.0\n",
            "Specificity :  0.9601990049751243\n",
            "false positive rate :  0.03980099502487562\n",
            "false negative rate :  0.0\n",
            "Negative Predictive Value :  1.0\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.02127659574468085\n",
            "10 fold cross validation:  [0.99337748 0.94701987 0.98013245 0.98013245 0.94666667 0.98666667\n",
            " 0.97333333 0.98666667 0.99333333 0.98      ]\n",
            "Mean of 10 fold cross validation :  0.9767328918322298\n"
          ]
        }
      ],
      "source": [
        "BC.fit(xtrain,ytrain)\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, BC.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, BC.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',BC.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",BC.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, BC.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, BC.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, BC.predict(xtest),average='macro'))\n",
        "probs = BC.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, BC.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(BC,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "bc=roc_auc_values(BC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20jba7LLNZX2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap_wMukcOysf"
      },
      "source": [
        "ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893
        },
        "id": "bt8H-4eMNZU5",
        "outputId": "d1381ac9-a9db-482f-a99a-41a7993ebe9c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.plot(gbc['fpr'], gbc['tpr'],   label='GBC (AUC = %0.3f)' % gbc['auc'])\n",
        "plt.plot(lgbm['fpr'], lgbm['tpr'],  label='LGBM (AUC = %0.3f)' % lgbm['auc'])\n",
        "plt.plot(bc['fpr'], bc['tpr'],  label='Bagging Classifier (AUC = %0.3f)' % bc['auc'])\n",
        "plt.plot(rf['fpr'], rf['tpr'], label='Random Forest (AUC = %0.3f)' % rf['auc'])\n",
        "plt.plot(etc['fpr'], etc['tpr'], label='Extra Tree (AUC = %0.3f)' % etc['auc'])\n",
        "plt.plot(hgb['fpr'], hgb['tpr'],  label='HGB(AUC = %0.3f)' % hgb['auc'])\n",
        "plt.plot(xgb['fpr'], xgb['tpr'], label='XG Boost (AUC = %0.3f)' % xgb['auc'])\n",
        "\n",
        "# Title\n",
        "plt.title('ROC Curve')\n",
        "# Axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# Show legend\n",
        "plt.legend() # \n",
        "# Show plot\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5CYi9mpNZR6",
        "outputId": "a8a9ae97-a0f9-4aaf-d699-a2d6d63203c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.26 ms, sys: 1.04 ms, total: 4.29 ms\n",
            "Wall time: 4.44 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "%%time\n",
        "XGB.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MYCyMLgz5_H",
        "outputId": "750cdcef-f6b2-4c77-db67-e53d60faa3cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16.3 ms, sys: 37 Âµs, total: 16.3 ms\n",
            "Wall time: 16.5 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "%%time\n",
        "RF.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENJx-ckbz5xa",
        "outputId": "31e65fda-e48b-413c-a19a-e8da0cefbd6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 19 ms, sys: 0 ns, total: 19 ms\n",
            "Wall time: 21.1 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "%%time\n",
        "ETC.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZrSei0TImlx",
        "outputId": "734a9a5c-5730-4f80-8afe-7bc303f202dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.81 ms, sys: 0 ns, total: 2.81 ms\n",
            "Wall time: 2.61 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "%%time\n",
        "SGDC.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf-5CTfvImKX",
        "outputId": "0a2625b7-ec9a-42ac-a497-613f1ef979c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.7 ms, sys: 5.72 ms, total: 10.4 ms\n",
            "Wall time: 7.87 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "%%time\n",
        "MLP.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz9pJ8ueImJd",
        "outputId": "a1d71ec7-a4a2-41a9-c48c-36a5a506a943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 10.7 ms, sys: 690 Âµs, total: 11.4 ms\n",
            "Wall time: 7.34 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "%%time\n",
        "HGB.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLIfggCaImIu",
        "outputId": "77a1b7fa-5893-48a5-e2a2-9cf56e52af26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.56 ms, sys: 8.08 ms, total: 12.6 ms\n",
            "Wall time: 9.01 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "%%time\n",
        "LGBM.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfQWvmdlImHR",
        "outputId": "1a2f84d4-e430-40f9-fc58-1f3196b15f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.73 ms, sys: 2.95 ms, total: 5.68 ms\n",
            "Wall time: 3.64 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "%%time\n",
        "GBC.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ulgvSnoImGR",
        "outputId": "95810412-b088-4beb-b920-00e516e8e9ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16.5 ms, sys: 8.14 ms, total: 24.6 ms\n",
            "Wall time: 12.7 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "%%time\n",
        "ABC.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhf6E-KDImEn",
        "outputId": "2c779640-77bb-4bba-de67-c0d62429e528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.03 ms, sys: 5 Âµs, total: 2.04 ms\n",
            "Wall time: 2.05 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "%%time\n",
        "DT.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoqYegDYIlxP",
        "outputId": "178a845b-7c95-44c4-f8f1-7ce0e31554ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 29.1 ms, sys: 10.8 ms, total: 39.9 ms\n",
            "Wall time: 30.2 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "%%time\n",
        "KNNC.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQeao9hHIluf",
        "outputId": "d00d4fef-8bf1-4798-8a37-2f094571c55a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 ms, sys: 2.24 ms, total: 6.23 ms\n",
            "Wall time: 3.65 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "%%time\n",
        "GNB.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHRT6pGaIlrU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgPpZdXGIlom"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ntr8gUMAIlkw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INQjjUSHP5oo"
      },
      "source": [
        "# ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTHTXPCBP63j"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "sc=StandardScaler()\n",
        "sc.fit(xtrain)\n",
        "\n",
        "xtrain_sc=sc.transform(xtrain)\n",
        "xtest_sc=sc.transform(xtest)\n",
        "\n",
        "xtrain_sc_df=pd.DataFrame(xtrain_sc,columns=xtrain.columns)\n",
        "xtest_sc_df=pd.DataFrame(xtest_sc,columns=xtrain.columns)\n",
        "\n",
        "xtrain=xtrain_sc_df\n",
        "xtest=xtest_sc_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFJNxaa6QEPL",
        "outputId": "ec22982a-3331-4485-fa5b-1b2d3469774f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.7/135.7 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.9.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (2.16.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.51.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (5.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (6.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.2)\n",
            "Installing collected packages: kt-legacy, jedi, keras-tuner\n",
            "Successfully installed jedi-0.18.2 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1awMJbWQSSz"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfkYfMbYQYR0"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    for i in range(hp.Int('num_layers', 2, 20)):\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                                            min_value=32,\n",
        "                                            max_value=512,\n",
        "                                            step=32),\n",
        "                               activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRcTey36QZa2"
      },
      "outputs": [],
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=15,\n",
        "    executions_per_trial=1,\n",
        "     directory='Typhoid',\n",
        "    project_name='Typhoid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4TH5cUcQa-W",
        "outputId": "1f998eb0-42ae-4e43-e0f0-a9330f30c85d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        }
      ],
      "source": [
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvpwIMIRQcae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cf6833-26b5-4c73-d39b-48b1a88b931b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 15 Complete [00h 00m 14s]\n",
            "val_accuracy: 0.982300877571106\n",
            "\n",
            "Best val_accuracy So Far: 0.991150438785553\n",
            "Total elapsed time: 00h 05m 37s\n"
          ]
        }
      ],
      "source": [
        "tuner.search(xtrain, ytrain,\n",
        "             epochs=50,\n",
        "             validation_split=0.2,#validation_data=(xtest, ytest)\n",
        "             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fa-JgmYQcXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef34bbcf-909c-475d-f745-932a88f9a455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in Typhoid/Typhoid\n",
            "Showing 1 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f3a1bc5f1f0>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 4\n",
            "units_0: 64\n",
            "units_1: 352\n",
            "learning_rate: 0.01\n",
            "units_2: 352\n",
            "units_3: 352\n",
            "units_4: 384\n",
            "units_5: 128\n",
            "units_6: 320\n",
            "units_7: 320\n",
            "units_8: 64\n",
            "units_9: 416\n",
            "units_10: 64\n",
            "Score: 0.991150438785553\n"
          ]
        }
      ],
      "source": [
        "tuner.results_summary(num_trials=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osVGpCz-QcU7"
      },
      "outputs": [],
      "source": [
        "besthp=tuner.get_best_hyperparameters(num_trials=1)[0]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B52ybCDmQcSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66913384-97c7-4092-bc23-2d30201f9777"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_tuner.engine.hyperparameters.HyperParameters at 0x7f3a7382b5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "besthp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbsSo2ypQcPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8dc66b-0a50-497a-9343-bcb032ca84b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01\n"
          ]
        }
      ],
      "source": [
        "print(besthp.get('learning_rate'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEnKH-T9QcMl"
      },
      "outputs": [],
      "source": [
        "model=tuner.hypermodel.build(besthp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQYp2FkvPqrp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8rixoxCMz7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9c8702a2-e74b-443c-e4db-89fd755ac764"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass MyThresholdCallback(tf.keras.callbacks.Callback):\\n    def __init__(self, threshold):\\n        super(MyThresholdCallback, self).__init__()\\n        self.threshold = threshold\\n        \\n    def on_epoch_end(self, epoch, logs=None):\\n      val_acc = logs[\"accuracy\"]\\n      if val_acc >= self.threshold:\\n        self.model.stop_training = True\\n\\ncallback=MyThresholdCallback(threshold=1.0)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "'''\n",
        "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(MyThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      val_acc = logs[\"accuracy\"]\n",
        "      if val_acc >= self.threshold:\n",
        "        self.model.stop_training = True\n",
        "\n",
        "callback=MyThresholdCallback(threshold=1.0)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5XTcuwHJyMA"
      },
      "outputs": [],
      "source": [
        "#callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0EFjrviQcJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3660bc0-752b-495e-b18f-c3d261963a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "29/29 [==============================] - 1s 12ms/step - loss: 0.3596 - accuracy: 0.9335 - val_loss: 0.1277 - val_accuracy: 0.9779\n",
            "Epoch 2/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.1384 - accuracy: 0.9712 - val_loss: 0.1061 - val_accuracy: 0.9779\n",
            "Epoch 3/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1130 - accuracy: 0.9712 - val_loss: 0.1085 - val_accuracy: 0.9823\n",
            "Epoch 4/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1071 - accuracy: 0.9723 - val_loss: 0.0920 - val_accuracy: 0.9823\n",
            "Epoch 5/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.9745 - val_loss: 0.1196 - val_accuracy: 0.9823\n",
            "Epoch 6/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0851 - accuracy: 0.9767 - val_loss: 0.1162 - val_accuracy: 0.9823\n",
            "Epoch 7/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0714 - accuracy: 0.9767 - val_loss: 0.1591 - val_accuracy: 0.9823\n",
            "Epoch 8/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0773 - accuracy: 0.9756 - val_loss: 0.1240 - val_accuracy: 0.9823\n",
            "Epoch 9/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0959 - accuracy: 0.9745 - val_loss: 0.1103 - val_accuracy: 0.9823\n",
            "Epoch 10/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9756 - val_loss: 0.1392 - val_accuracy: 0.9823\n",
            "Epoch 11/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9767 - val_loss: 0.1564 - val_accuracy: 0.9823\n",
            "Epoch 12/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0669 - accuracy: 0.9767 - val_loss: 0.1919 - val_accuracy: 0.9823\n",
            "Epoch 13/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0586 - accuracy: 0.9767 - val_loss: 0.1816 - val_accuracy: 0.9823\n",
            "Epoch 14/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0618 - accuracy: 0.9767 - val_loss: 0.1724 - val_accuracy: 0.9823\n",
            "Epoch 15/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9767 - val_loss: 0.1390 - val_accuracy: 0.9823\n",
            "Epoch 16/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9778 - val_loss: 0.2969 - val_accuracy: 0.9823\n",
            "Epoch 17/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9767 - val_loss: 0.2953 - val_accuracy: 0.9602\n",
            "Epoch 18/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1959 - accuracy: 0.9534 - val_loss: 0.0798 - val_accuracy: 0.9823\n",
            "Epoch 19/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.1284 - accuracy: 0.9723 - val_loss: 0.0844 - val_accuracy: 0.9823\n",
            "Epoch 20/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1209 - accuracy: 0.9734 - val_loss: 0.0887 - val_accuracy: 0.9823\n",
            "Epoch 21/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9745 - val_loss: 0.0996 - val_accuracy: 0.9823\n",
            "Epoch 22/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9745 - val_loss: 0.0980 - val_accuracy: 0.9823\n",
            "Epoch 23/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9745 - val_loss: 0.1031 - val_accuracy: 0.9823\n",
            "Epoch 24/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9745 - val_loss: 0.1238 - val_accuracy: 0.9823\n",
            "Epoch 25/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9778 - val_loss: 0.1371 - val_accuracy: 0.9823\n",
            "Epoch 26/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9789 - val_loss: 0.1861 - val_accuracy: 0.9823\n",
            "Epoch 27/500\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9778 - val_loss: 0.1463 - val_accuracy: 0.9823\n",
            "Epoch 28/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.9789 - val_loss: 0.1652 - val_accuracy: 0.9823\n",
            "Epoch 29/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9789 - val_loss: 0.1902 - val_accuracy: 0.9823\n",
            "Epoch 30/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9745 - val_loss: 0.1452 - val_accuracy: 0.9823\n",
            "Epoch 31/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.9800 - val_loss: 0.1582 - val_accuracy: 0.9779\n",
            "Epoch 32/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9778 - val_loss: 0.2105 - val_accuracy: 0.9823\n",
            "Epoch 33/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.9778 - val_loss: 0.1496 - val_accuracy: 0.9779\n",
            "Epoch 34/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9789 - val_loss: 0.2165 - val_accuracy: 0.9646\n",
            "Epoch 35/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9778 - val_loss: 0.5941 - val_accuracy: 0.9513\n",
            "Epoch 36/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.9656 - val_loss: 0.0906 - val_accuracy: 0.9823\n",
            "Epoch 37/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.3131 - accuracy: 0.9723 - val_loss: 0.2163 - val_accuracy: 0.9690\n",
            "Epoch 38/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1319 - accuracy: 0.9667 - val_loss: 0.1337 - val_accuracy: 0.9779\n",
            "Epoch 39/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9734 - val_loss: 0.1240 - val_accuracy: 0.9823\n",
            "Epoch 40/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0923 - accuracy: 0.9745 - val_loss: 0.1097 - val_accuracy: 0.9779\n",
            "Epoch 41/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9745 - val_loss: 0.1282 - val_accuracy: 0.9823\n",
            "Epoch 42/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9745 - val_loss: 0.1265 - val_accuracy: 0.9823\n",
            "Epoch 43/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0707 - accuracy: 0.9745 - val_loss: 0.1431 - val_accuracy: 0.9823\n",
            "Epoch 44/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9745 - val_loss: 0.1835 - val_accuracy: 0.9823\n",
            "Epoch 45/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9745 - val_loss: 0.2196 - val_accuracy: 0.9823\n",
            "Epoch 46/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9678 - val_loss: 0.1574 - val_accuracy: 0.9823\n",
            "Epoch 47/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9756 - val_loss: 0.1769 - val_accuracy: 0.9823\n",
            "Epoch 48/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9701 - val_loss: 0.1939 - val_accuracy: 0.9823\n",
            "Epoch 49/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9756 - val_loss: 0.1712 - val_accuracy: 0.9823\n",
            "Epoch 50/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0641 - accuracy: 0.9756 - val_loss: 0.1737 - val_accuracy: 0.9823\n",
            "Epoch 51/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9734 - val_loss: 0.2592 - val_accuracy: 0.9823\n",
            "Epoch 52/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9723 - val_loss: 0.2570 - val_accuracy: 0.9779\n",
            "Epoch 53/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0642 - accuracy: 0.9745 - val_loss: 0.2878 - val_accuracy: 0.9823\n",
            "Epoch 54/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 0.9767 - val_loss: 0.3638 - val_accuracy: 0.9823\n",
            "Epoch 55/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0579 - accuracy: 0.9756 - val_loss: 0.3950 - val_accuracy: 0.9823\n",
            "Epoch 56/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0641 - accuracy: 0.9767 - val_loss: 0.2728 - val_accuracy: 0.9823\n",
            "Epoch 57/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9756 - val_loss: 0.1688 - val_accuracy: 0.9823\n",
            "Epoch 58/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9745 - val_loss: 0.2557 - val_accuracy: 0.9823\n",
            "Epoch 59/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9756 - val_loss: 0.3289 - val_accuracy: 0.9735\n",
            "Epoch 60/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.9767 - val_loss: 0.2520 - val_accuracy: 0.9690\n",
            "Epoch 61/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9823 - val_loss: 0.3570 - val_accuracy: 0.9690\n",
            "Epoch 62/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 0.9800 - val_loss: 0.2981 - val_accuracy: 0.9779\n",
            "Epoch 63/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9856 - val_loss: 0.3355 - val_accuracy: 0.9823\n",
            "Epoch 64/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9856 - val_loss: 0.3353 - val_accuracy: 0.9823\n",
            "Epoch 65/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9834 - val_loss: 0.3343 - val_accuracy: 0.9823\n",
            "Epoch 66/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9878 - val_loss: 0.3706 - val_accuracy: 0.9779\n",
            "Epoch 67/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9845 - val_loss: 0.3852 - val_accuracy: 0.9646\n",
            "Epoch 68/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 0.9878 - val_loss: 0.4191 - val_accuracy: 0.9779\n",
            "Epoch 69/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0613 - accuracy: 0.9834 - val_loss: 0.4204 - val_accuracy: 0.9735\n",
            "Epoch 70/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0933 - accuracy: 0.9778 - val_loss: 0.5095 - val_accuracy: 0.9779\n",
            "Epoch 71/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9767 - val_loss: 0.1686 - val_accuracy: 0.9779\n",
            "Epoch 72/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9812 - val_loss: 0.1837 - val_accuracy: 0.9513\n",
            "Epoch 73/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9789 - val_loss: 0.3236 - val_accuracy: 0.9690\n",
            "Epoch 74/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.9789 - val_loss: 0.2277 - val_accuracy: 0.9690\n",
            "Epoch 75/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9834 - val_loss: 0.2762 - val_accuracy: 0.9735\n",
            "Epoch 76/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0392 - accuracy: 0.9845 - val_loss: 0.3157 - val_accuracy: 0.9735\n",
            "Epoch 77/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9645 - val_loss: 0.3329 - val_accuracy: 0.9823\n",
            "Epoch 78/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9834 - val_loss: 0.4441 - val_accuracy: 0.9823\n",
            "Epoch 79/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9800 - val_loss: 0.4209 - val_accuracy: 0.9779\n",
            "Epoch 80/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9823 - val_loss: 0.4757 - val_accuracy: 0.9735\n",
            "Epoch 81/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9812 - val_loss: 0.5113 - val_accuracy: 0.9735\n",
            "Epoch 82/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0384 - accuracy: 0.9845 - val_loss: 0.4289 - val_accuracy: 0.9336\n",
            "Epoch 83/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9823 - val_loss: 0.5053 - val_accuracy: 0.9558\n",
            "Epoch 84/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 0.9845 - val_loss: 0.4798 - val_accuracy: 0.9469\n",
            "Epoch 85/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9800 - val_loss: 0.5910 - val_accuracy: 0.9646\n",
            "Epoch 86/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9789 - val_loss: 0.5879 - val_accuracy: 0.9425\n",
            "Epoch 87/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0341 - accuracy: 0.9823 - val_loss: 0.4808 - val_accuracy: 0.9513\n",
            "Epoch 88/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9867 - val_loss: 0.5905 - val_accuracy: 0.9735\n",
            "Epoch 89/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9845 - val_loss: 0.7685 - val_accuracy: 0.9735\n",
            "Epoch 90/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0316 - accuracy: 0.9823 - val_loss: 0.6098 - val_accuracy: 0.9558\n",
            "Epoch 91/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0531 - accuracy: 0.9712 - val_loss: 0.5503 - val_accuracy: 0.9690\n",
            "Epoch 92/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0612 - accuracy: 0.9756 - val_loss: 0.5841 - val_accuracy: 0.9646\n",
            "Epoch 93/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9845 - val_loss: 0.7174 - val_accuracy: 0.9690\n",
            "Epoch 94/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9823 - val_loss: 0.7058 - val_accuracy: 0.9602\n",
            "Epoch 95/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9845 - val_loss: 0.6136 - val_accuracy: 0.9690\n",
            "Epoch 96/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9834 - val_loss: 0.6612 - val_accuracy: 0.9690\n",
            "Epoch 97/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.9845 - val_loss: 0.7929 - val_accuracy: 0.9735\n",
            "Epoch 98/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0326 - accuracy: 0.9856 - val_loss: 0.7935 - val_accuracy: 0.9690\n",
            "Epoch 99/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9834 - val_loss: 0.9498 - val_accuracy: 0.9735\n",
            "Epoch 100/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9867 - val_loss: 0.9609 - val_accuracy: 0.9690\n",
            "Epoch 101/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0378 - accuracy: 0.9845 - val_loss: 0.9042 - val_accuracy: 0.9690\n",
            "Epoch 102/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9834 - val_loss: 0.6606 - val_accuracy: 0.9558\n",
            "Epoch 103/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9878 - val_loss: 0.8692 - val_accuracy: 0.9735\n",
            "Epoch 104/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9856 - val_loss: 0.8519 - val_accuracy: 0.9690\n",
            "Epoch 105/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.8680 - val_accuracy: 0.9558\n",
            "Epoch 106/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9878 - val_loss: 1.0062 - val_accuracy: 0.9646\n",
            "Epoch 107/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0397 - accuracy: 0.9845 - val_loss: 0.9141 - val_accuracy: 0.9513\n",
            "Epoch 108/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9845 - val_loss: 0.6378 - val_accuracy: 0.9602\n",
            "Epoch 109/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9856 - val_loss: 0.6976 - val_accuracy: 0.9558\n",
            "Epoch 110/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9889 - val_loss: 0.9477 - val_accuracy: 0.9646\n",
            "Epoch 111/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.2248 - accuracy: 0.9845 - val_loss: 0.2288 - val_accuracy: 0.9469\n",
            "Epoch 112/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.9767 - val_loss: 0.2270 - val_accuracy: 0.9735\n",
            "Epoch 113/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9767 - val_loss: 0.4371 - val_accuracy: 0.9779\n",
            "Epoch 114/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9778 - val_loss: 0.4711 - val_accuracy: 0.9779\n",
            "Epoch 115/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9834 - val_loss: 0.5000 - val_accuracy: 0.9513\n",
            "Epoch 116/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9690 - val_loss: 0.5859 - val_accuracy: 0.9735\n",
            "Epoch 117/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9745 - val_loss: 0.4709 - val_accuracy: 0.9336\n",
            "Epoch 118/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1799 - accuracy: 0.9723 - val_loss: 0.3335 - val_accuracy: 0.9646\n",
            "Epoch 119/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 3.0997 - accuracy: 0.9568 - val_loss: 4.4401 - val_accuracy: 0.9690\n",
            "Epoch 120/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 2.1524 - accuracy: 0.9734 - val_loss: 0.2012 - val_accuracy: 0.9823\n",
            "Epoch 121/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1677 - accuracy: 0.9667 - val_loss: 0.1431 - val_accuracy: 0.9779\n",
            "Epoch 122/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.1256 - accuracy: 0.9645 - val_loss: 0.2364 - val_accuracy: 0.9735\n",
            "Epoch 123/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9701 - val_loss: 0.4023 - val_accuracy: 0.9779\n",
            "Epoch 124/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1813 - accuracy: 0.9734 - val_loss: 0.1614 - val_accuracy: 0.9823\n",
            "Epoch 125/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9712 - val_loss: 0.1274 - val_accuracy: 0.9823\n",
            "Epoch 126/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9734 - val_loss: 0.1972 - val_accuracy: 0.9823\n",
            "Epoch 127/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0691 - accuracy: 0.9745 - val_loss: 0.1756 - val_accuracy: 0.9823\n",
            "Epoch 128/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9734 - val_loss: 0.2231 - val_accuracy: 0.9823\n",
            "Epoch 129/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9767 - val_loss: 0.1767 - val_accuracy: 0.9823\n",
            "Epoch 130/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9690 - val_loss: 0.2231 - val_accuracy: 0.9823\n",
            "Epoch 131/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0648 - accuracy: 0.9756 - val_loss: 0.2361 - val_accuracy: 0.9823\n",
            "Epoch 132/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0554 - accuracy: 0.9745 - val_loss: 0.2850 - val_accuracy: 0.9823\n",
            "Epoch 133/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9800 - val_loss: 0.2762 - val_accuracy: 0.9690\n",
            "Epoch 134/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9812 - val_loss: 0.2851 - val_accuracy: 0.9779\n",
            "Epoch 135/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 0.9812 - val_loss: 0.3024 - val_accuracy: 0.9823\n",
            "Epoch 136/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9800 - val_loss: 0.2719 - val_accuracy: 0.9823\n",
            "Epoch 137/500\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9789 - val_loss: 0.3588 - val_accuracy: 0.9823\n",
            "Epoch 138/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0503 - accuracy: 0.9823 - val_loss: 0.3502 - val_accuracy: 0.9735\n",
            "Epoch 139/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0409 - accuracy: 0.9834 - val_loss: 0.4276 - val_accuracy: 0.9779\n",
            "Epoch 140/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0575 - accuracy: 0.9712 - val_loss: 0.4080 - val_accuracy: 0.9602\n",
            "Epoch 141/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 0.9812 - val_loss: 0.3444 - val_accuracy: 0.9779\n",
            "Epoch 142/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9789 - val_loss: 0.4354 - val_accuracy: 0.9779\n",
            "Epoch 143/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.9834 - val_loss: 0.4116 - val_accuracy: 0.9735\n",
            "Epoch 144/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9823 - val_loss: 0.4286 - val_accuracy: 0.9602\n",
            "Epoch 145/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0392 - accuracy: 0.9823 - val_loss: 0.4671 - val_accuracy: 0.9558\n",
            "Epoch 146/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9823 - val_loss: 0.4369 - val_accuracy: 0.9558\n",
            "Epoch 147/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 0.9823 - val_loss: 0.4323 - val_accuracy: 0.9558\n",
            "Epoch 148/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.9823 - val_loss: 0.3634 - val_accuracy: 0.9558\n",
            "Epoch 149/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0520 - accuracy: 0.9756 - val_loss: 0.4494 - val_accuracy: 0.9469\n",
            "Epoch 150/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9789 - val_loss: 0.3882 - val_accuracy: 0.9602\n",
            "Epoch 151/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9845 - val_loss: 0.4613 - val_accuracy: 0.9602\n",
            "Epoch 152/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9867 - val_loss: 0.4757 - val_accuracy: 0.9646\n",
            "Epoch 153/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9867 - val_loss: 0.5337 - val_accuracy: 0.9558\n",
            "Epoch 154/500\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9812 - val_loss: 0.4815 - val_accuracy: 0.9602\n",
            "Epoch 155/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0425 - accuracy: 0.9778 - val_loss: 0.4920 - val_accuracy: 0.9602\n",
            "Epoch 156/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9878 - val_loss: 0.5513 - val_accuracy: 0.9646\n",
            "Epoch 157/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9645 - val_loss: 0.3612 - val_accuracy: 0.9513\n",
            "Epoch 158/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0540 - accuracy: 0.9800 - val_loss: 0.4188 - val_accuracy: 0.9646\n",
            "Epoch 159/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9778 - val_loss: 0.6024 - val_accuracy: 0.9779\n",
            "Epoch 160/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9756 - val_loss: 0.4758 - val_accuracy: 0.9646\n",
            "Epoch 161/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9789 - val_loss: 0.5412 - val_accuracy: 0.9779\n",
            "Epoch 162/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.9667 - val_loss: 0.5076 - val_accuracy: 0.9823\n",
            "Epoch 163/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9823 - val_loss: 0.5871 - val_accuracy: 0.9823\n",
            "Epoch 164/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9856 - val_loss: 0.6044 - val_accuracy: 0.9646\n",
            "Epoch 165/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9856 - val_loss: 0.5927 - val_accuracy: 0.9469\n",
            "Epoch 166/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0364 - accuracy: 0.9867 - val_loss: 0.7327 - val_accuracy: 0.9646\n",
            "Epoch 167/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 0.9856 - val_loss: 0.6664 - val_accuracy: 0.9646\n",
            "Epoch 168/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9856 - val_loss: 0.7472 - val_accuracy: 0.9602\n",
            "Epoch 169/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9845 - val_loss: 0.7446 - val_accuracy: 0.9602\n",
            "Epoch 170/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9878 - val_loss: 0.7895 - val_accuracy: 0.9690\n",
            "Epoch 171/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 0.7432 - val_accuracy: 0.9602\n",
            "Epoch 172/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9845 - val_loss: 0.7732 - val_accuracy: 0.9779\n",
            "Epoch 173/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.9867 - val_loss: 0.5406 - val_accuracy: 0.9513\n",
            "Epoch 174/500\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9812 - val_loss: 0.6815 - val_accuracy: 0.9602\n",
            "Epoch 175/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9812 - val_loss: 0.5298 - val_accuracy: 0.9425\n",
            "Epoch 176/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9867 - val_loss: 0.7683 - val_accuracy: 0.9646\n",
            "Epoch 177/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9856 - val_loss: 0.7925 - val_accuracy: 0.9602\n",
            "Epoch 178/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0628 - accuracy: 0.9690 - val_loss: 0.4215 - val_accuracy: 0.9248\n",
            "Epoch 179/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9745 - val_loss: 0.5918 - val_accuracy: 0.9558\n",
            "Epoch 180/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9834 - val_loss: 0.7195 - val_accuracy: 0.9602\n",
            "Epoch 181/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0354 - accuracy: 0.9867 - val_loss: 0.8035 - val_accuracy: 0.9602\n",
            "Epoch 182/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9845 - val_loss: 0.7163 - val_accuracy: 0.9425\n",
            "Epoch 183/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0343 - accuracy: 0.9856 - val_loss: 0.9017 - val_accuracy: 0.9646\n",
            "Epoch 184/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9878 - val_loss: 0.9709 - val_accuracy: 0.9602\n",
            "Epoch 185/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9889 - val_loss: 0.9980 - val_accuracy: 0.9602\n",
            "Epoch 186/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0310 - accuracy: 0.9867 - val_loss: 0.9550 - val_accuracy: 0.9735\n",
            "Epoch 187/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9845 - val_loss: 0.8741 - val_accuracy: 0.9513\n",
            "Epoch 188/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9745 - val_loss: 0.6192 - val_accuracy: 0.9513\n",
            "Epoch 189/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9834 - val_loss: 0.8163 - val_accuracy: 0.9823\n",
            "Epoch 190/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.5813 - val_accuracy: 0.9602\n",
            "Epoch 191/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9856 - val_loss: 0.7070 - val_accuracy: 0.9602\n",
            "Epoch 192/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.6406 - val_accuracy: 0.9602\n",
            "Epoch 193/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.9867 - val_loss: 0.7361 - val_accuracy: 0.9690\n",
            "Epoch 194/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9878 - val_loss: 0.8502 - val_accuracy: 0.9602\n",
            "Epoch 195/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9856 - val_loss: 0.8100 - val_accuracy: 0.9558\n",
            "Epoch 196/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9856 - val_loss: 0.9633 - val_accuracy: 0.9690\n",
            "Epoch 197/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9812 - val_loss: 0.6079 - val_accuracy: 0.9646\n",
            "Epoch 198/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9856 - val_loss: 0.7568 - val_accuracy: 0.9779\n",
            "Epoch 199/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9823 - val_loss: 0.7131 - val_accuracy: 0.9646\n",
            "Epoch 200/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1305 - accuracy: 0.9623 - val_loss: 0.4047 - val_accuracy: 0.9248\n",
            "Epoch 201/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.9568 - val_loss: 0.6008 - val_accuracy: 0.9779\n",
            "Epoch 202/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.9623 - val_loss: 0.7907 - val_accuracy: 0.9823\n",
            "Epoch 203/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9778 - val_loss: 0.5994 - val_accuracy: 0.9469\n",
            "Epoch 204/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.9789 - val_loss: 0.6196 - val_accuracy: 0.9823\n",
            "Epoch 205/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9834 - val_loss: 1.0771 - val_accuracy: 0.9381\n",
            "Epoch 206/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.2464 - accuracy: 0.9579 - val_loss: 0.4783 - val_accuracy: 0.9425\n",
            "Epoch 207/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.9734 - val_loss: 0.5015 - val_accuracy: 0.9646\n",
            "Epoch 208/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9723 - val_loss: 0.6966 - val_accuracy: 0.9779\n",
            "Epoch 209/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9812 - val_loss: 0.7880 - val_accuracy: 0.9823\n",
            "Epoch 210/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9800 - val_loss: 0.7775 - val_accuracy: 0.9690\n",
            "Epoch 211/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9878 - val_loss: 0.9583 - val_accuracy: 0.9779\n",
            "Epoch 212/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9867 - val_loss: 0.7868 - val_accuracy: 0.9558\n",
            "Epoch 213/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 0.9756 - val_loss: 0.6718 - val_accuracy: 0.9823\n",
            "Epoch 214/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9856 - val_loss: 0.7029 - val_accuracy: 0.9735\n",
            "Epoch 215/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 0.9856 - val_loss: 0.8275 - val_accuracy: 0.9779\n",
            "Epoch 216/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9867 - val_loss: 0.7460 - val_accuracy: 0.9646\n",
            "Epoch 217/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 0.9154 - val_accuracy: 0.9779\n",
            "Epoch 218/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9845 - val_loss: 0.8810 - val_accuracy: 0.9646\n",
            "Epoch 219/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 1.0063 - val_accuracy: 0.9558\n",
            "Epoch 220/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0310 - accuracy: 0.9878 - val_loss: 1.0810 - val_accuracy: 0.9735\n",
            "Epoch 221/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.9900 - val_loss: 0.6688 - val_accuracy: 0.9646\n",
            "Epoch 222/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9889 - val_loss: 0.7577 - val_accuracy: 0.9646\n",
            "Epoch 223/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.8776 - val_accuracy: 0.9690\n",
            "Epoch 224/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9911 - val_loss: 0.9651 - val_accuracy: 0.9690\n",
            "Epoch 225/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0573 - accuracy: 0.9756 - val_loss: 0.6835 - val_accuracy: 0.9469\n",
            "Epoch 226/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0424 - accuracy: 0.9800 - val_loss: 0.6604 - val_accuracy: 0.9690\n",
            "Epoch 227/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9889 - val_loss: 0.6694 - val_accuracy: 0.9558\n",
            "Epoch 228/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9856 - val_loss: 0.8628 - val_accuracy: 0.9646\n",
            "Epoch 229/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9922 - val_loss: 0.8773 - val_accuracy: 0.9690\n",
            "Epoch 230/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 0.9900 - val_loss: 0.9034 - val_accuracy: 0.9558\n",
            "Epoch 231/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9878 - val_loss: 0.9984 - val_accuracy: 0.9646\n",
            "Epoch 232/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9812 - val_loss: 0.8523 - val_accuracy: 0.9602\n",
            "Epoch 233/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9823 - val_loss: 0.8885 - val_accuracy: 0.9558\n",
            "Epoch 234/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9911 - val_loss: 1.0775 - val_accuracy: 0.9690\n",
            "Epoch 235/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 0.9922 - val_loss: 1.0033 - val_accuracy: 0.9602\n",
            "Epoch 236/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 1.2621 - val_accuracy: 0.9690\n",
            "Epoch 237/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9834 - val_loss: 0.9839 - val_accuracy: 0.9558\n",
            "Epoch 238/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9856 - val_loss: 1.2321 - val_accuracy: 0.9690\n",
            "Epoch 239/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9911 - val_loss: 1.0917 - val_accuracy: 0.9513\n",
            "Epoch 240/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9845 - val_loss: 1.3447 - val_accuracy: 0.9690\n",
            "Epoch 241/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 1.4223 - val_accuracy: 0.9690\n",
            "Epoch 242/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 1.4093 - val_accuracy: 0.9558\n",
            "Epoch 243/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 1.2265 - val_accuracy: 0.9558\n",
            "Epoch 244/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0372 - accuracy: 0.9823 - val_loss: 1.1033 - val_accuracy: 0.9425\n",
            "Epoch 245/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0300 - accuracy: 0.9856 - val_loss: 1.2825 - val_accuracy: 0.9602\n",
            "Epoch 246/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9834 - val_loss: 1.1814 - val_accuracy: 0.9513\n",
            "Epoch 247/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9856 - val_loss: 1.2460 - val_accuracy: 0.9513\n",
            "Epoch 248/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 0.9789 - val_loss: 1.2130 - val_accuracy: 0.9558\n",
            "Epoch 249/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 0.9867 - val_loss: 1.4040 - val_accuracy: 0.9690\n",
            "Epoch 250/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9867 - val_loss: 1.3309 - val_accuracy: 0.9513\n",
            "Epoch 251/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 0.9878 - val_loss: 1.4754 - val_accuracy: 0.9690\n",
            "Epoch 252/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0227 - accuracy: 0.9900 - val_loss: 1.6639 - val_accuracy: 0.9735\n",
            "Epoch 253/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9900 - val_loss: 1.5352 - val_accuracy: 0.9602\n",
            "Epoch 254/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 1.5516 - val_accuracy: 0.9823\n",
            "Epoch 255/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9834 - val_loss: 0.7819 - val_accuracy: 0.9425\n",
            "Epoch 256/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9778 - val_loss: 1.1967 - val_accuracy: 0.9646\n",
            "Epoch 257/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9856 - val_loss: 1.2877 - val_accuracy: 0.9646\n",
            "Epoch 258/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9856 - val_loss: 1.5096 - val_accuracy: 0.9646\n",
            "Epoch 259/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.2389 - accuracy: 0.9789 - val_loss: 2.0566 - val_accuracy: 0.9823\n",
            "Epoch 260/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1699 - accuracy: 0.9723 - val_loss: 0.9176 - val_accuracy: 0.9469\n",
            "Epoch 261/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.9745 - val_loss: 0.8118 - val_accuracy: 0.9646\n",
            "Epoch 262/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0411 - accuracy: 0.9845 - val_loss: 1.2160 - val_accuracy: 0.9735\n",
            "Epoch 263/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0661 - accuracy: 0.9834 - val_loss: 0.8736 - val_accuracy: 0.9690\n",
            "Epoch 264/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9867 - val_loss: 1.0100 - val_accuracy: 0.9646\n",
            "Epoch 265/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 0.9856 - val_loss: 0.9347 - val_accuracy: 0.9558\n",
            "Epoch 266/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9856 - val_loss: 1.2125 - val_accuracy: 0.9735\n",
            "Epoch 267/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0260 - accuracy: 0.9900 - val_loss: 1.3782 - val_accuracy: 0.9646\n",
            "Epoch 268/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0492 - accuracy: 0.9878 - val_loss: 1.8363 - val_accuracy: 0.9513\n",
            "Epoch 269/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9845 - val_loss: 2.0523 - val_accuracy: 0.9425\n",
            "Epoch 270/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 0.9867 - val_loss: 1.9507 - val_accuracy: 0.9469\n",
            "Epoch 271/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9856 - val_loss: 1.9611 - val_accuracy: 0.9469\n",
            "Epoch 272/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0283 - accuracy: 0.9889 - val_loss: 2.0621 - val_accuracy: 0.9602\n",
            "Epoch 273/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9867 - val_loss: 2.0451 - val_accuracy: 0.9602\n",
            "Epoch 274/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9900 - val_loss: 2.1638 - val_accuracy: 0.9558\n",
            "Epoch 275/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0216 - accuracy: 0.9900 - val_loss: 2.0894 - val_accuracy: 0.9513\n",
            "Epoch 276/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9878 - val_loss: 1.9821 - val_accuracy: 0.9469\n",
            "Epoch 277/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 0.9878 - val_loss: 1.9583 - val_accuracy: 0.9558\n",
            "Epoch 278/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 1.6764 - val_accuracy: 0.9602\n",
            "Epoch 279/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9900 - val_loss: 1.7227 - val_accuracy: 0.9735\n",
            "Epoch 280/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0190 - accuracy: 0.9911 - val_loss: 1.8784 - val_accuracy: 0.9735\n",
            "Epoch 281/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 1.9858 - val_accuracy: 0.9779\n",
            "Epoch 282/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9900 - val_loss: 1.3502 - val_accuracy: 0.9513\n",
            "Epoch 283/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9889 - val_loss: 1.5224 - val_accuracy: 0.9735\n",
            "Epoch 284/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.9800 - val_loss: 1.1925 - val_accuracy: 0.9469\n",
            "Epoch 285/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9834 - val_loss: 1.6487 - val_accuracy: 0.9823\n",
            "Epoch 286/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 0.9878 - val_loss: 1.3447 - val_accuracy: 0.9646\n",
            "Epoch 287/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9878 - val_loss: 1.4743 - val_accuracy: 0.9646\n",
            "Epoch 288/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.9878 - val_loss: 1.3488 - val_accuracy: 0.9469\n",
            "Epoch 289/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0457 - accuracy: 0.9800 - val_loss: 0.9615 - val_accuracy: 0.9735\n",
            "Epoch 290/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9778 - val_loss: 1.0408 - val_accuracy: 0.9513\n",
            "Epoch 291/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 0.9900 - val_loss: 1.6323 - val_accuracy: 0.9602\n",
            "Epoch 292/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9889 - val_loss: 2.0406 - val_accuracy: 0.9558\n",
            "Epoch 293/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9900 - val_loss: 1.8310 - val_accuracy: 0.9513\n",
            "Epoch 294/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9900 - val_loss: 1.9228 - val_accuracy: 0.9558\n",
            "Epoch 295/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 0.9878 - val_loss: 1.9211 - val_accuracy: 0.9558\n",
            "Epoch 296/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 0.9878 - val_loss: 1.9479 - val_accuracy: 0.9469\n",
            "Epoch 297/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 1.7614 - val_accuracy: 0.9425\n",
            "Epoch 298/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0234 - accuracy: 0.9911 - val_loss: 1.8779 - val_accuracy: 0.9558\n",
            "Epoch 299/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0189 - accuracy: 0.9922 - val_loss: 1.9828 - val_accuracy: 0.9513\n",
            "Epoch 300/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0196 - accuracy: 0.9911 - val_loss: 1.9938 - val_accuracy: 0.9513\n",
            "Epoch 301/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0167 - accuracy: 0.9911 - val_loss: 2.0568 - val_accuracy: 0.9602\n",
            "Epoch 302/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0475 - accuracy: 0.9800 - val_loss: 1.1039 - val_accuracy: 0.9602\n",
            "Epoch 303/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.9767 - val_loss: 1.4636 - val_accuracy: 0.9735\n",
            "Epoch 304/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9867 - val_loss: 1.4515 - val_accuracy: 0.9602\n",
            "Epoch 305/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9867 - val_loss: 1.3773 - val_accuracy: 0.9779\n",
            "Epoch 306/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 0.9889 - val_loss: 1.5112 - val_accuracy: 0.9381\n",
            "Epoch 307/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9867 - val_loss: 1.3099 - val_accuracy: 0.9690\n",
            "Epoch 308/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 0.9900 - val_loss: 1.4335 - val_accuracy: 0.9690\n",
            "Epoch 309/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 0.9878 - val_loss: 1.5053 - val_accuracy: 0.9425\n",
            "Epoch 310/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0406 - accuracy: 0.9856 - val_loss: 1.3779 - val_accuracy: 0.9602\n",
            "Epoch 311/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0231 - accuracy: 0.9900 - val_loss: 1.7161 - val_accuracy: 0.9779\n",
            "Epoch 312/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 0.9867 - val_loss: 1.7585 - val_accuracy: 0.9690\n",
            "Epoch 313/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 0.9867 - val_loss: 1.6927 - val_accuracy: 0.9558\n",
            "Epoch 314/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0243 - accuracy: 0.9889 - val_loss: 1.6306 - val_accuracy: 0.9823\n",
            "Epoch 315/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0421 - accuracy: 0.9845 - val_loss: 1.8049 - val_accuracy: 0.9823\n",
            "Epoch 316/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 1.6731 - val_accuracy: 0.9602\n",
            "Epoch 317/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0205 - accuracy: 0.9922 - val_loss: 1.6137 - val_accuracy: 0.9602\n",
            "Epoch 318/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0190 - accuracy: 0.9911 - val_loss: 1.9746 - val_accuracy: 0.9558\n",
            "Epoch 319/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9922 - val_loss: 2.0472 - val_accuracy: 0.9558\n",
            "Epoch 320/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9900 - val_loss: 7.3778 - val_accuracy: 0.7345\n",
            "Epoch 321/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.3014 - accuracy: 0.9590 - val_loss: 3.5883 - val_accuracy: 0.9690\n",
            "Epoch 322/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0799 - accuracy: 0.9678 - val_loss: 3.8845 - val_accuracy: 0.9823\n",
            "Epoch 323/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0912 - accuracy: 0.9712 - val_loss: 2.8082 - val_accuracy: 0.9646\n",
            "Epoch 324/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0764 - accuracy: 0.9723 - val_loss: 3.1670 - val_accuracy: 0.9779\n",
            "Epoch 325/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0722 - accuracy: 0.9745 - val_loss: 8.6315 - val_accuracy: 0.9779\n",
            "Epoch 326/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9756 - val_loss: 6.6418 - val_accuracy: 0.9779\n",
            "Epoch 327/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0930 - accuracy: 0.9756 - val_loss: 6.1531 - val_accuracy: 0.9779\n",
            "Epoch 328/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.6272 - accuracy: 0.9701 - val_loss: 0.3129 - val_accuracy: 0.9779\n",
            "Epoch 329/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1281 - accuracy: 0.9701 - val_loss: 1.9439 - val_accuracy: 0.9823\n",
            "Epoch 330/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1647 - accuracy: 0.9734 - val_loss: 0.6542 - val_accuracy: 0.9823\n",
            "Epoch 331/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1013 - accuracy: 0.9734 - val_loss: 0.1664 - val_accuracy: 0.9823\n",
            "Epoch 332/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.9734 - val_loss: 0.1454 - val_accuracy: 0.9779\n",
            "Epoch 333/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.2303 - accuracy: 0.9712 - val_loss: 0.2083 - val_accuracy: 0.9823\n",
            "Epoch 334/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.9734 - val_loss: 0.2128 - val_accuracy: 0.9823\n",
            "Epoch 335/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.9734 - val_loss: 0.2226 - val_accuracy: 0.9823\n",
            "Epoch 336/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.9734 - val_loss: 0.2300 - val_accuracy: 0.9823\n",
            "Epoch 337/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.9734 - val_loss: 0.2479 - val_accuracy: 0.9823\n",
            "Epoch 338/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 0.2677 - val_accuracy: 0.9823\n",
            "Epoch 339/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 0.3001 - val_accuracy: 0.9823\n",
            "Epoch 340/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 0.3898 - val_accuracy: 0.9823\n",
            "Epoch 341/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.9734 - val_loss: 0.5220 - val_accuracy: 0.9823\n",
            "Epoch 342/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9734 - val_loss: 0.6499 - val_accuracy: 0.9823\n",
            "Epoch 343/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9734 - val_loss: 0.7806 - val_accuracy: 0.9823\n",
            "Epoch 344/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1024 - accuracy: 0.9734 - val_loss: 0.8659 - val_accuracy: 0.9823\n",
            "Epoch 345/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.9734 - val_loss: 1.2362 - val_accuracy: 0.9823\n",
            "Epoch 346/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0968 - accuracy: 0.9734 - val_loss: 1.5024 - val_accuracy: 0.9823\n",
            "Epoch 347/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9734 - val_loss: 0.6417 - val_accuracy: 0.9823\n",
            "Epoch 348/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1012 - accuracy: 0.9734 - val_loss: 0.6673 - val_accuracy: 0.9823\n",
            "Epoch 349/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1015 - accuracy: 0.9734 - val_loss: 0.9355 - val_accuracy: 0.9823\n",
            "Epoch 350/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.9734 - val_loss: 1.0279 - val_accuracy: 0.9823\n",
            "Epoch 351/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0992 - accuracy: 0.9734 - val_loss: 1.3129 - val_accuracy: 0.9823\n",
            "Epoch 352/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1350 - accuracy: 0.9734 - val_loss: 0.7431 - val_accuracy: 0.9823\n",
            "Epoch 353/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.9734 - val_loss: 0.6613 - val_accuracy: 0.9823\n",
            "Epoch 354/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9734 - val_loss: 0.6772 - val_accuracy: 0.9823\n",
            "Epoch 355/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 0.9213 - val_accuracy: 0.9823\n",
            "Epoch 356/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1051 - accuracy: 0.9734 - val_loss: 0.9922 - val_accuracy: 0.9823\n",
            "Epoch 357/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0373 - val_accuracy: 0.9823\n",
            "Epoch 358/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9734 - val_loss: 1.0201 - val_accuracy: 0.9823\n",
            "Epoch 359/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.9734 - val_loss: 1.0165 - val_accuracy: 0.9823\n",
            "Epoch 360/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0251 - val_accuracy: 0.9823\n",
            "Epoch 361/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1074 - accuracy: 0.9734 - val_loss: 1.0269 - val_accuracy: 0.9823\n",
            "Epoch 362/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1050 - accuracy: 0.9734 - val_loss: 1.0561 - val_accuracy: 0.9823\n",
            "Epoch 363/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9734 - val_loss: 1.0628 - val_accuracy: 0.9823\n",
            "Epoch 364/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9734 - val_loss: 1.0188 - val_accuracy: 0.9823\n",
            "Epoch 365/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0166 - val_accuracy: 0.9823\n",
            "Epoch 366/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0430 - val_accuracy: 0.9823\n",
            "Epoch 367/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0510 - val_accuracy: 0.9823\n",
            "Epoch 368/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.9734 - val_loss: 1.0230 - val_accuracy: 0.9823\n",
            "Epoch 369/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0400 - val_accuracy: 0.9823\n",
            "Epoch 370/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.9734 - val_loss: 1.0685 - val_accuracy: 0.9823\n",
            "Epoch 371/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.0546 - val_accuracy: 0.9823\n",
            "Epoch 372/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0554 - val_accuracy: 0.9823\n",
            "Epoch 373/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9734 - val_loss: 1.0518 - val_accuracy: 0.9823\n",
            "Epoch 374/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1048 - accuracy: 0.9734 - val_loss: 1.0775 - val_accuracy: 0.9823\n",
            "Epoch 375/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.0593 - val_accuracy: 0.9823\n",
            "Epoch 376/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 1.0382 - val_accuracy: 0.9823\n",
            "Epoch 377/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0808 - val_accuracy: 0.9823\n",
            "Epoch 378/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9734 - val_loss: 1.0695 - val_accuracy: 0.9823\n",
            "Epoch 379/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0500 - val_accuracy: 0.9823\n",
            "Epoch 380/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0470 - val_accuracy: 0.9823\n",
            "Epoch 381/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.9734 - val_loss: 1.0521 - val_accuracy: 0.9823\n",
            "Epoch 382/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0705 - val_accuracy: 0.9823\n",
            "Epoch 383/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9734 - val_loss: 1.0548 - val_accuracy: 0.9823\n",
            "Epoch 384/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.0636 - val_accuracy: 0.9823\n",
            "Epoch 385/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0595 - val_accuracy: 0.9823\n",
            "Epoch 386/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0950 - val_accuracy: 0.9823\n",
            "Epoch 387/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9734 - val_loss: 1.0454 - val_accuracy: 0.9823\n",
            "Epoch 388/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0679 - val_accuracy: 0.9823\n",
            "Epoch 389/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0719 - val_accuracy: 0.9823\n",
            "Epoch 390/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.0619 - val_accuracy: 0.9823\n",
            "Epoch 391/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0544 - val_accuracy: 0.9823\n",
            "Epoch 392/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0489 - val_accuracy: 0.9823\n",
            "Epoch 393/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0447 - val_accuracy: 0.9823\n",
            "Epoch 394/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.9734 - val_loss: 1.0636 - val_accuracy: 0.9823\n",
            "Epoch 395/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0656 - val_accuracy: 0.9823\n",
            "Epoch 396/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.9734 - val_loss: 1.0550 - val_accuracy: 0.9823\n",
            "Epoch 397/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0710 - val_accuracy: 0.9823\n",
            "Epoch 398/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.0665 - val_accuracy: 0.9823\n",
            "Epoch 399/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0637 - val_accuracy: 0.9823\n",
            "Epoch 400/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.9734 - val_loss: 1.0537 - val_accuracy: 0.9823\n",
            "Epoch 401/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0582 - val_accuracy: 0.9823\n",
            "Epoch 402/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0739 - val_accuracy: 0.9823\n",
            "Epoch 403/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0601 - val_accuracy: 0.9823\n",
            "Epoch 404/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0704 - val_accuracy: 0.9823\n",
            "Epoch 405/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0554 - val_accuracy: 0.9823\n",
            "Epoch 406/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1053 - accuracy: 0.9734 - val_loss: 1.0877 - val_accuracy: 0.9823\n",
            "Epoch 407/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.0513 - val_accuracy: 0.9823\n",
            "Epoch 408/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.9734 - val_loss: 1.0646 - val_accuracy: 0.9823\n",
            "Epoch 409/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9734 - val_loss: 1.0567 - val_accuracy: 0.9823\n",
            "Epoch 410/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 1.0486 - val_accuracy: 0.9823\n",
            "Epoch 411/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9734 - val_loss: 1.0883 - val_accuracy: 0.9823\n",
            "Epoch 412/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0503 - val_accuracy: 0.9823\n",
            "Epoch 413/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0669 - val_accuracy: 0.9823\n",
            "Epoch 414/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0577 - val_accuracy: 0.9823\n",
            "Epoch 415/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1052 - accuracy: 0.9734 - val_loss: 1.0531 - val_accuracy: 0.9823\n",
            "Epoch 416/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0649 - val_accuracy: 0.9823\n",
            "Epoch 417/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.0473 - val_accuracy: 0.9823\n",
            "Epoch 418/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.0590 - val_accuracy: 0.9823\n",
            "Epoch 419/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.0586 - val_accuracy: 0.9823\n",
            "Epoch 420/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.9734 - val_loss: 1.0727 - val_accuracy: 0.9823\n",
            "Epoch 421/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.9734 - val_loss: 1.0573 - val_accuracy: 0.9823\n",
            "Epoch 422/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1051 - accuracy: 0.9734 - val_loss: 1.0387 - val_accuracy: 0.9823\n",
            "Epoch 423/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1036 - accuracy: 0.9734 - val_loss: 1.0727 - val_accuracy: 0.9823\n",
            "Epoch 424/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 1.0632 - val_accuracy: 0.9823\n",
            "Epoch 425/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1039 - accuracy: 0.9734 - val_loss: 1.0575 - val_accuracy: 0.9823\n",
            "Epoch 426/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.9734 - val_loss: 1.0425 - val_accuracy: 0.9823\n",
            "Epoch 427/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1037 - accuracy: 0.9734 - val_loss: 1.0808 - val_accuracy: 0.9823\n",
            "Epoch 428/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1053 - accuracy: 0.9734 - val_loss: 1.0427 - val_accuracy: 0.9823\n",
            "Epoch 429/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.1038 - accuracy: 0.9734 - val_loss: 1.0571 - val_accuracy: 0.9823\n",
            "Epoch 430/500\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 1.0555 - val_accuracy: 0.9823\n",
            "Epoch 431/500\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.0385 - val_accuracy: 0.9823\n",
            "Epoch 432/500\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0802 - val_accuracy: 0.9823\n",
            "Epoch 433/500\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.0449 - val_accuracy: 0.9823\n",
            "Epoch 434/500\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0253 - val_accuracy: 0.9823\n",
            "Epoch 435/500\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.1053 - accuracy: 0.9734 - val_loss: 1.0527 - val_accuracy: 0.9823\n",
            "Epoch 436/500\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0507 - val_accuracy: 0.9823\n",
            "Epoch 437/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.1039 - accuracy: 0.9734 - val_loss: 1.0684 - val_accuracy: 0.9823\n",
            "Epoch 438/500\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.0515 - val_accuracy: 0.9823\n",
            "Epoch 439/500\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.0669 - val_accuracy: 0.9823\n",
            "Epoch 440/500\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0524 - val_accuracy: 0.9823\n",
            "Epoch 441/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.1050 - accuracy: 0.9734 - val_loss: 1.0428 - val_accuracy: 0.9823\n",
            "Epoch 442/500\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0457 - val_accuracy: 0.9823\n",
            "Epoch 443/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.1037 - accuracy: 0.9734 - val_loss: 1.0610 - val_accuracy: 0.9823\n",
            "Epoch 444/500\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0590 - val_accuracy: 0.9823\n",
            "Epoch 445/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1053 - accuracy: 0.9734 - val_loss: 1.0233 - val_accuracy: 0.9823\n",
            "Epoch 446/500\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.1048 - accuracy: 0.9734 - val_loss: 1.0328 - val_accuracy: 0.9823\n",
            "Epoch 447/500\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1046 - accuracy: 0.9734 - val_loss: 1.0599 - val_accuracy: 0.9823\n",
            "Epoch 448/500\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.0418 - val_accuracy: 0.9823\n",
            "Epoch 449/500\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.1038 - accuracy: 0.9734 - val_loss: 1.0708 - val_accuracy: 0.9823\n",
            "Epoch 450/500\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.1045 - accuracy: 0.9734 - val_loss: 1.0491 - val_accuracy: 0.9823\n",
            "Epoch 451/500\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.1052 - accuracy: 0.9734 - val_loss: 1.0437 - val_accuracy: 0.9823\n",
            "Epoch 452/500\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.1038 - accuracy: 0.9734 - val_loss: 1.0419 - val_accuracy: 0.9823\n",
            "Epoch 453/500\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.0527 - val_accuracy: 0.9823\n",
            "Epoch 454/500\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.0456 - val_accuracy: 0.9823\n",
            "Epoch 455/500\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.0519 - val_accuracy: 0.9823\n",
            "Epoch 456/500\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.0513 - val_accuracy: 0.9823\n",
            "Epoch 457/500\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.0578 - val_accuracy: 0.9823\n",
            "Epoch 458/500\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0498 - val_accuracy: 0.9823\n",
            "Epoch 459/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.0415 - val_accuracy: 0.9823\n",
            "Epoch 460/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.0484 - val_accuracy: 0.9823\n",
            "Epoch 461/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9734 - val_loss: 1.0592 - val_accuracy: 0.9823\n",
            "Epoch 462/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1052 - accuracy: 0.9734 - val_loss: 1.0068 - val_accuracy: 0.9823\n",
            "Epoch 463/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.9734 - val_loss: 1.0572 - val_accuracy: 0.9823\n",
            "Epoch 464/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 1.0379 - val_accuracy: 0.9823\n",
            "Epoch 465/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1044 - accuracy: 0.9734 - val_loss: 1.0457 - val_accuracy: 0.9823\n",
            "Epoch 466/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.9734 - val_loss: 1.0552 - val_accuracy: 0.9823\n",
            "Epoch 467/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 1.0354 - val_accuracy: 0.9823\n",
            "Epoch 468/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.9734 - val_loss: 1.0518 - val_accuracy: 0.9823\n",
            "Epoch 469/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1038 - accuracy: 0.9734 - val_loss: 1.0420 - val_accuracy: 0.9823\n",
            "Epoch 470/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1046 - accuracy: 0.9734 - val_loss: 1.0525 - val_accuracy: 0.9823\n",
            "Epoch 471/500\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9734 - val_loss: 1.0506 - val_accuracy: 0.9823\n",
            "Epoch 472/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.0416 - val_accuracy: 0.9823\n",
            "Epoch 473/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.9734 - val_loss: 1.0518 - val_accuracy: 0.9823\n",
            "Epoch 474/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.0455 - val_accuracy: 0.9823\n",
            "Epoch 475/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 1.0702 - val_accuracy: 0.9823\n",
            "Epoch 476/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1047 - accuracy: 0.9734 - val_loss: 1.0279 - val_accuracy: 0.9823\n",
            "Epoch 477/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.9734 - val_loss: 0.9397 - val_accuracy: 0.9823\n",
            "Epoch 478/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.5262 - val_accuracy: 0.9823\n",
            "Epoch 479/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.5749 - val_accuracy: 0.9823\n",
            "Epoch 480/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1046 - accuracy: 0.9734 - val_loss: 1.5886 - val_accuracy: 0.9823\n",
            "Epoch 481/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9734 - val_loss: 1.5863 - val_accuracy: 0.9823\n",
            "Epoch 482/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1038 - accuracy: 0.9734 - val_loss: 1.5720 - val_accuracy: 0.9823\n",
            "Epoch 483/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.5693 - val_accuracy: 0.9823\n",
            "Epoch 484/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.5810 - val_accuracy: 0.9823\n",
            "Epoch 485/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.5877 - val_accuracy: 0.9823\n",
            "Epoch 486/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1042 - accuracy: 0.9734 - val_loss: 1.5600 - val_accuracy: 0.9823\n",
            "Epoch 487/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.5568 - val_accuracy: 0.9823\n",
            "Epoch 488/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.5688 - val_accuracy: 0.9823\n",
            "Epoch 489/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 1.5400 - val_accuracy: 0.9823\n",
            "Epoch 490/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.5894 - val_accuracy: 0.9823\n",
            "Epoch 491/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.9734 - val_loss: 1.5613 - val_accuracy: 0.9823\n",
            "Epoch 492/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9734 - val_loss: 1.5546 - val_accuracy: 0.9823\n",
            "Epoch 493/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.5717 - val_accuracy: 0.9823\n",
            "Epoch 494/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 1.5875 - val_accuracy: 0.9823\n",
            "Epoch 495/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 1.5226 - val_accuracy: 0.9823\n",
            "Epoch 496/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1046 - accuracy: 0.9734 - val_loss: 1.5675 - val_accuracy: 0.9823\n",
            "Epoch 497/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.5544 - val_accuracy: 0.9823\n",
            "Epoch 498/500\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.9734 - val_loss: 1.5273 - val_accuracy: 0.9823\n",
            "Epoch 499/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 1.5402 - val_accuracy: 0.9823\n",
            "Epoch 500/500\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 1.5685 - val_accuracy: 0.9823\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(xtrain,ytrain,epochs=500,\n",
        "                 # validation_data=(xtest, ytest))\n",
        "                  validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etmcn7_VQkFB"
      },
      "outputs": [],
      "source": [
        "r=history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpR9RlKsQlJx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d11df3dc-d13b-4150-94ad-699bd6e9e50f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "plt.plot(r.history['accuracy'], label = 'accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DBjBZK0QlGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc08cd6f-4fbd-4d6b-d30e-b375abae8707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "y_pred = model.predict(xtest)\n",
        "y_pred = y_pred > 0.5\n",
        "le2 = LabelEncoder()\n",
        "y_pred = le.fit_transform(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSGQdmE2QncH"
      },
      "outputs": [],
      "source": [
        "# metrics\n",
        "acc_score = accuracy_score(ytest, y_pred)\n",
        "cm = confusion_matrix(ytest, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er0VsDt4Qo5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80f0b7e9-cb88-4cac-dfe2-1c6bad060e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.973404255319149\n"
          ]
        }
      ],
      "source": [
        "print(acc_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmnD_4hQQqBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ea0bb6-c623-470c-91a4-7b5daa270f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[173  10]\n",
            " [  0 193]]\n"
          ]
        }
      ],
      "source": [
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi_3kUbURKLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2e35cb-11dc-45a0-eed6-52be77b9069f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[173  10]\n",
            " [  0 193]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97       183\n",
            "           1       0.95      1.00      0.97       193\n",
            "\n",
            "    accuracy                           0.97       376\n",
            "   macro avg       0.98      0.97      0.97       376\n",
            "weighted avg       0.97      0.97      0.97       376\n",
            "\n",
            "\n",
            "\n",
            "F1 Score : 0.9733287935535127\n",
            "Precision : 0.9753694581280787\n",
            "Recall : 0.9726775956284153\n",
            "Sensitivity :  1.0\n",
            "Specificity :  0.9507389162561576\n",
            "false positive rate :  0.04926108374384237\n",
            "false negative rate :  0.0\n",
            "Negative Predictive Value :  1.0\n",
            "False Discovery rate :  0.0546448087431694\n",
            "Mean Absolute Error: 0.026595744680851064\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, y_pred)\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, y_pred)\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print(\"F1 Score :\",f1_score(ytest, y_pred,average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, y_pred,average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, y_pred,average='macro'))\n",
        "\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOsK9EELR1NY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phbnNzx6338-"
      },
      "source": [
        "# Hyper parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVYXvld131mb"
      },
      "outputs": [],
      "source": [
        "## Hyper Parameter Optimization\n",
        "max_depth = [int(x) for x in np.linspace(10, 11110, num = 11)]\n",
        "params={\n",
        " \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
        "# \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
        " \"max_depth\"        : max_depth,\n",
        " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
        " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
        " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
        "    \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYoQNpMy30cZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6186fc37-4ed8-41d6-e654-f2c8038ea942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 5280 candidates, totalling 10560 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, estimator=XGBClassifier(), n_jobs=-1,\n",
              "             param_grid={'colsample_bytree': [0.3, 0.4, 0.5, 0.7],\n",
              "                         'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
              "                         'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
              "                         'max_depth': [10, 1120, 2230, 3340, 4450, 5560, 6670,\n",
              "                                       7780, 8890, 10000, 11110],\n",
              "                         'min_child_weight': [1, 3, 5, 7]},\n",
              "             verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "## Hyperparameter optimization using RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "import xgboost\n",
        "classifier=xgboost.XGBClassifier()\n",
        "#rf_randomcv=RandomizedSearchCV(estimator=classifier,param_distributions=params,n_iter=500,cv=2,verbose=2,\n",
        "                          #     random_state=100,n_jobs=-1)\n",
        "\n",
        "rf_randomcv=GridSearchCV(estimator=classifier,param_grid=params,cv=2,verbose=2,\n",
        "                               n_jobs=-1)\n",
        "\n",
        "### fit the randomized model\n",
        "rf_randomcv.fit(xtrain,ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGIZGYAF4Q6r"
      },
      "outputs": [],
      "source": [
        "best_random_grid=rf_randomcv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT-xL94E4Q3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f529a845-147b-4244-de66-d18014a1dccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[175   8]\n",
            " [  2 191]]\n",
            "Accuracy Score 0.973404255319149\n",
            "Classification report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97       183\n",
            "           1       0.96      0.99      0.97       193\n",
            "\n",
            "    accuracy                           0.97       376\n",
            "   macro avg       0.97      0.97      0.97       376\n",
            "weighted avg       0.97      0.97      0.97       376\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred=best_random_grid.predict(xtest)\n",
        "print(confusion_matrix(ytest,y_pred))\n",
        "print(\"Accuracy Score {}\".format(accuracy_score(ytest,y_pred)))\n",
        "print(\"Classification report: {}\".format(classification_report(ytest,y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydzaYbC-4Q0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b7de87-c09a-4f08-f241-ab2e86f2aa08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(colsample_bytree=0.4, gamma=0.0, max_depth=10)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "best_random_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJaeA-E_4Qxv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEajb66Q4uQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641ee803-8dfd-43f1-c36c-af2e34bc6429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix is :\n",
            "[[175   8]\n",
            " [  2 191]]\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97       183\n",
            "           1       0.96      0.99      0.97       193\n",
            "\n",
            "    accuracy                           0.97       376\n",
            "   macro avg       0.97      0.97      0.97       376\n",
            "weighted avg       0.97      0.97      0.97       376\n",
            "\n",
            "\n",
            "\n",
            "Testing accuracy :  0.973404255319149\n",
            "Training accuracy: 97.96099290780141\n",
            "F1 Score : 0.9733560090702947\n",
            "Precision : 0.974249779973313\n",
            "Recall : 0.9729607293524731\n",
            "AUC = 0.981\n",
            "Sensitivity :  0.9887005649717514\n",
            "Specificity :  0.9597989949748744\n",
            "false positive rate :  0.04020100502512563\n",
            "false negative rate :  0.011299435028248588\n",
            "Negative Predictive Value :  0.9896373056994818\n",
            "False Discovery rate :  0.04371584699453552\n",
            "Mean Absolute Error: 0.026595744680851064\n",
            "10 fold cross validation:  [0.99337748 0.94701987 0.97350993 0.98013245 0.94666667 0.98\n",
            " 0.97333333 0.98666667 0.98666667 0.98      ]\n",
            "Mean of 10 fold cross validation :  0.9747373068432671\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print('Confusion matrix is :')\n",
        "cm = confusion_matrix(ytest, best_random_grid.predict(xtest))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "classificationReport = classification_report(ytest, best_random_grid.predict(xtest))\n",
        "print(\"Classification Report : \")\n",
        "print (classificationReport)\n",
        "print(\"\\n\")\n",
        "print('Testing accuracy : ',best_random_grid.score(xtest,ytest))\n",
        "print(\"Training accuracy:\",best_random_grid.score(xtrain,ytrain)*100)\n",
        "print(\"F1 Score :\",f1_score(ytest, best_random_grid.predict(xtest),average='macro'))\n",
        "print(\"Precision :\", precision_score(ytest, best_random_grid.predict(xtest),average='macro'))\n",
        "print(\"Recall :\", recall_score(ytest, best_random_grid.predict(xtest),average='macro'))\n",
        "probs = best_random_grid.predict_proba(xtest)\n",
        "probs = probs[:, 1]\n",
        "auc = roc_auc_score(ytest, probs)\n",
        "fpr, tpr, _ = roc_curve(ytest, probs)\n",
        "auc1=metrics.auc(fpr, tpr)\n",
        "print('AUC = %.3f' % (auc1))\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, best_random_grid.predict(xtest)))\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=10)\n",
        "scores=cross_val_score(best_random_grid,x,y,cv=skfold)\n",
        "print(\"10 fold cross validation: \",scores)\n",
        "print(\"Mean of 10 fold cross validation : \",np.mean(scores))\n",
        "gnb=roc_auc_values(best_random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWcwLLVU4t6M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI5z_SDG4t29"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jslW2L6YE9qZ",
        "s3iZkagRIDKv",
        "v5pw9Hx1J6yr",
        "INQjjUSHP5oo",
        "phbnNzx6338-"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}